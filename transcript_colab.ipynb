{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# 🎯 Audio Transcription with Whisper on Google Colab\n",
        "\n",
        "This notebook allows you to transcribe audio files from your Google Drive using OpenAI's Whisper model with GPU acceleration.\n",
        "\n",
        "## Features:\n",
        "- 🚀 **GPU Acceleration** - Automatically uses Colab's free GPU for faster processing\n",
        "- 📁 **Google Drive Integration** - Read audio files directly from your Drive\n",
        "- 🌐 **Multi-language Support** - English, Portuguese, and auto-detection\n",
        "- 📄 **Multiple Output Formats** - TXT, SRT, VTT for subtitles\n",
        "- 💾 **Auto-save to Drive** - Results saved back to your Google Drive\n",
        "\n",
        "## Instructions:\n",
        "1. Run all cells in order\n",
        "2. Authorize Google Drive access when prompted\n",
        "3. Specify your audio file path\n",
        "4. Get your transcription!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def check_gpu():\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(\"✅ GPU is available!\")\n",
        "            print(\"\\nGPU Details:\")\n",
        "            # Extract GPU name\n",
        "            for line in result.stdout.split('\\n'):\n",
        "                if 'Tesla' in line or 'GeForce' in line or 'RTX' in line:\n",
        "                    print(f\"  {line.strip()}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"❌ No GPU detected. Please enable GPU in Runtime > Change runtime type > GPU\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error checking GPU: {e}\")\n",
        "        return False\n",
        "\n",
        "# Check if we have GPU\n",
        "has_gpu = check_gpu()\n",
        "\n",
        "# Also check PyTorch CUDA availability\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"\\n✅ PyTorch CUDA is available\")\n",
        "        print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "except ImportError:\n",
        "    print(\"\\n⚠️  PyTorch not installed yet - will be installed in next step\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"📦 Installing dependencies...\")\n",
        "print(\"This may take a few minutes...\\n\")\n",
        "\n",
        "# Install faster-whisper and other requirements\n",
        "!pip install -q faster-whisper\n",
        "!pip install -q rich\n",
        "\n",
        "print(\"\\n✅ Dependencies installed successfully!\")\n",
        "\n",
        "# Verify installation\n",
        "try:\n",
        "    from faster_whisper import WhisperModel\n",
        "    import rich\n",
        "    print(\"✅ All imports working correctly\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import error: {e}\")\n",
        "    print(\"Please restart the runtime and try again\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"🔗 Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\"\\n✅ Google Drive mounted successfully!\")\n",
        "print(\"\\nYour Drive structure:\")\n",
        "print(\"  📁 /content/drive/MyDrive/\")\n",
        "\n",
        "# List some folders in Drive\n",
        "try:\n",
        "    folders = os.listdir('/content/drive/MyDrive/')[:5]\n",
        "    for folder in folders:\n",
        "        print(f\"     └── {folder}\")\n",
        "    if len(os.listdir('/content/drive/MyDrive/')) > 5:\n",
        "        print(\"     └── ...\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not list folders: {e}\")\n",
        "\n",
        "# Create audio folders if they don't exist\n",
        "audio_dir = Path(\"/content/drive/MyDrive/audio\")\n",
        "transcriptions_dir = Path(\"/content/drive/MyDrive/transcriptions\")\n",
        "\n",
        "if not audio_dir.exists():\n",
        "    audio_dir.mkdir(parents=True)\n",
        "    print(f\"\\n📁 Created folder: {audio_dir}\")\n",
        "    print(\"   → Place your audio files here!\")\n",
        "    \n",
        "if not transcriptions_dir.exists():\n",
        "    transcriptions_dir.mkdir(parents=True)\n",
        "    print(f\"📁 Created folder: {transcriptions_dir}\")\n",
        "    print(\"   → Transcriptions will be saved here (optional)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core transcription functions\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple\n",
        "import torch\n",
        "from faster_whisper import WhisperModel\n",
        "from rich.console import Console\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "\n",
        "console = Console()\n",
        "\n",
        "def detect_device_and_compute_type(force_cpu: bool = False) -> Tuple[str, str]:\n",
        "    \"\"\"Detect if GPU is available and return appropriate device and compute type.\"\"\"\n",
        "    if force_cpu:\n",
        "        console.print(\"[yellow]ℹ[/yellow] Using CPU (forced)\")\n",
        "        return \"cpu\", \"int8\"\n",
        "        \n",
        "    try:\n",
        "        import torch\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "            \n",
        "            console.print(f\"[green]✓[/green] GPU detected: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
        "            \n",
        "            # Use float16 for GPUs with compute capability >= 7.0\n",
        "            gpu_capability = torch.cuda.get_device_capability(0)\n",
        "            \n",
        "            if gpu_capability[0] >= 7:\n",
        "                return \"cuda\", \"float16\"\n",
        "            else:\n",
        "                return \"cuda\", \"int8\"\n",
        "        else:\n",
        "            console.print(\"[yellow]ℹ[/yellow] No GPU detected, using CPU\")\n",
        "            return \"cpu\", \"int8\"\n",
        "            \n",
        "    except Exception as e:\n",
        "        console.print(f\"[yellow]⚠[/yellow] Error detecting GPU: {e}\")\n",
        "        return \"cpu\", \"int8\"\n",
        "\n",
        "def load_whisper_model(model_size: str = \"base\", force_cpu: bool = False) -> WhisperModel:\n",
        "    \"\"\"Load the Whisper model with progress indicator.\"\"\"\n",
        "    device, compute_type = detect_device_and_compute_type(force_cpu)\n",
        "    \n",
        "    with console.status(\n",
        "        f\"[bold cyan]Loading Whisper {model_size} model on {device.upper()}...[/bold cyan]\",\n",
        "        spinner=\"dots12\",\n",
        "    ):\n",
        "        model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "        console.print(f\"[green]✓[/green] Model loaded successfully on {device.upper()}!\")\n",
        "    return model\n",
        "\n",
        "def format_timestamp(seconds):\n",
        "    \"\"\"Convert seconds to timestamp format\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = seconds % 60\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:06.3f}\"\n",
        "\n",
        "def transcribe_file(\n",
        "    audio_file: Path,\n",
        "    model: WhisperModel,\n",
        "    language: Optional[str] = None,\n",
        "    output_format: str = \"txt\",\n",
        "    output_dir: Optional[Path] = None,\n",
        "    multilingual: bool = False\n",
        ") -> dict:\n",
        "    \"\"\"Transcribe a single audio file.\"\"\"\n",
        "    \n",
        "    if not audio_file.exists():\n",
        "        raise FileNotFoundError(f\"Audio file not found: {audio_file}\")\n",
        "    \n",
        "    # Set output directory\n",
        "    if output_dir is None:\n",
        "        output_dir = audio_file.parent\n",
        "    \n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Create output file paths\n",
        "    base_name = audio_file.stem\n",
        "    output_files = {}\n",
        "    \n",
        "    if output_format == \"all\":\n",
        "        formats = [\"txt\", \"srt\", \"vtt\"]\n",
        "    else:\n",
        "        formats = [output_format]\n",
        "    \n",
        "    for fmt in formats:\n",
        "        output_files[fmt] = output_dir / f\"{base_name}.{fmt}\"\n",
        "    \n",
        "    # Start transcription\n",
        "    console.print(f\"\\n[cyan]Transcribing:[/cyan] {audio_file.name}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Create progress bar\n",
        "    with Progress(\n",
        "        SpinnerColumn(),\n",
        "        TextColumn(\"[progress.description]{task.description}\"),\n",
        "        BarColumn(),\n",
        "        TaskProgressColumn(),\n",
        "        TimeElapsedColumn(),\n",
        "        console=console,\n",
        "    ) as progress:\n",
        "        \n",
        "        task = progress.add_task(\"[cyan]Processing...\", total=None)\n",
        "        \n",
        "        # Transcribe\n",
        "        segments, info = model.transcribe(\n",
        "            str(audio_file),\n",
        "            language=language,\n",
        "            beam_size=5,\n",
        "            vad_filter=True,\n",
        "            vad_parameters=dict(min_silence_duration_ms=500),\n",
        "            multilingual=multilingual,\n",
        "        )\n",
        "        \n",
        "        # Process segments\n",
        "        all_segments = []\n",
        "        segment_count = 0\n",
        "        \n",
        "        # Update progress to show segment processing\n",
        "        progress.update(task, total=100, completed=0, description=\"[yellow]Writing segments...\")\n",
        "        \n",
        "        for segment in segments:\n",
        "            segment_count += 1\n",
        "            all_segments.append(segment)\n",
        "            \n",
        "            # Update progress\n",
        "            if segment_count % 10 == 0:\n",
        "                progress.update(task, advance=10)\n",
        "        \n",
        "        progress.update(task, completed=100, description=\"[green]Complete!\")\n",
        "    \n",
        "    # Write output files\n",
        "    for fmt, output_file in output_files.items():\n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            if fmt == \"txt\":\n",
        "                if info.language and not multilingual:\n",
        "                    f.write(f\"[Detected language: {info.language}]\\n\\n\")\n",
        "                elif multilingual:\n",
        "                    f.write(\"[Multilingual transcription]\\n\\n\")\n",
        "                \n",
        "                for segment in all_segments:\n",
        "                    if multilingual and hasattr(segment, \"language\"):\n",
        "                        f.write(f\"[{segment.language}] {segment.text.strip()}\\n\")\n",
        "                    else:\n",
        "                        f.write(f\"{segment.text.strip()}\\n\")\n",
        "            \n",
        "            elif fmt == \"srt\":\n",
        "                for i, segment in enumerate(all_segments, 1):\n",
        "                    f.write(f\"{i}\\n\")\n",
        "                    start = format_timestamp(segment.start).replace(\".\", \",\")\n",
        "                    end = format_timestamp(segment.end).replace(\".\", \",\")\n",
        "                    f.write(f\"{start} --> {end}\\n\")\n",
        "                    if multilingual and hasattr(segment, \"language\"):\n",
        "                        f.write(f\"[{segment.language}] {segment.text.strip()}\\n\\n\")\n",
        "                    else:\n",
        "                        f.write(f\"{segment.text.strip()}\\n\\n\")\n",
        "            \n",
        "            elif fmt == \"vtt\":\n",
        "                f.write(\"WEBVTT\\n\\n\")\n",
        "                for segment in all_segments:\n",
        "                    start = format_timestamp(segment.start)\n",
        "                    end = format_timestamp(segment.end)\n",
        "                    f.write(f\"{start} --> {end}\\n\")\n",
        "                    if multilingual and hasattr(segment, \"language\"):\n",
        "                        f.write(f\"[{segment.language}] {segment.text.strip()}\\n\\n\")\n",
        "                    else:\n",
        "                        f.write(f\"{segment.text.strip()}\\n\\n\")\n",
        "    \n",
        "    # Calculate statistics\n",
        "    duration = time.time() - start_time\n",
        "    audio_duration = info.duration\n",
        "    speed = audio_duration / duration if duration > 0 else 0\n",
        "    \n",
        "    # Show results\n",
        "    console.print(f\"\\n[green]✓[/green] Transcription complete!\")\n",
        "    console.print(f\"  Audio duration: {audio_duration:.1f}s\")\n",
        "    console.print(f\"  Processing time: {duration:.1f}s\")\n",
        "    console.print(f\"  Speed: {speed:.1f}x realtime\")\n",
        "    console.print(f\"  Segments: {segment_count}\")\n",
        "    if info.language:\n",
        "        console.print(f\"  Language: {info.language}\")\n",
        "    \n",
        "    console.print(f\"\\n[green]Output files:[/green]\")\n",
        "    for fmt, output_file in output_files.items():\n",
        "        console.print(f\"  📄 {output_file}\")\n",
        "    \n",
        "    return {\n",
        "        \"audio_duration\": audio_duration,\n",
        "        \"processing_time\": duration,\n",
        "        \"segments\": segment_count,\n",
        "        \"language\": info.language,\n",
        "        \"output_files\": output_files\n",
        "    }\n",
        "\n",
        "print(\"✅ Transcription functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - Modify these settings as needed\n",
        "\n",
        "# Audio file path in Google Drive\n",
        "# Examples:\n",
        "#   Single file: \"/content/drive/MyDrive/audio/interview.mp3\"\n",
        "#   Folder: \"/content/drive/MyDrive/audio_files/\"\n",
        "AUDIO_PATH = \"/content/drive/MyDrive/audio/sample.mp3\"  # Change this to your file/folder\n",
        "\n",
        "# Output directory (where to save transcriptions)\n",
        "# Leave as None to save in the same folder as the audio files\n",
        "OUTPUT_DIR = None  # or \"/content/drive/MyDrive/transcriptions/\"\n",
        "\n",
        "# Model size: \"tiny\", \"base\", \"small\", \"medium\", \"large\"\n",
        "# Larger models are more accurate but slower\n",
        "MODEL_SIZE = \"base\"\n",
        "\n",
        "# Language: \"en\" (English), \"pt\" (Portuguese), None (auto-detect)\n",
        "LANGUAGE = None  # Auto-detect\n",
        "\n",
        "# Output format: \"txt\", \"srt\", \"vtt\", \"all\"\n",
        "OUTPUT_FORMAT = \"txt\"\n",
        "\n",
        "# Enable multilingual mode (detect language changes within audio)\n",
        "MULTILINGUAL = False\n",
        "\n",
        "# Force CPU usage (set to True if you want to use CPU instead of GPU)\n",
        "FORCE_CPU = False\n",
        "\n",
        "print(\"📋 Configuration:\")\n",
        "print(f\"  Audio path: {AUDIO_PATH}\")\n",
        "print(f\"  Output directory: {OUTPUT_DIR or 'Same as audio files'}\")\n",
        "print(f\"  Model size: {MODEL_SIZE}\")\n",
        "print(f\"  Language: {LANGUAGE or 'Auto-detect'}\")\n",
        "print(f\"  Output format: {OUTPUT_FORMAT}\")\n",
        "print(f\"  Multilingual: {MULTILINGUAL}\")\n",
        "print(f\"  Force CPU: {FORCE_CPU}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model and run transcription\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Supported audio formats\n",
        "AUDIO_EXTENSIONS = {\n",
        "    \".mp3\", \".wav\", \".flac\", \".ogg\", \".m4a\", \".mp4\",\n",
        "    \".aac\", \".wma\", \".opus\", \".webm\", \".mkv\", \".avi\", \".mov\", \".m4v\",\n",
        "}\n",
        "\n",
        "def get_audio_files(path_str: str):\n",
        "    \"\"\"Get list of audio files from path (file or directory).\"\"\"\n",
        "    path = Path(path_str)\n",
        "    \n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"Path not found: {path}\")\n",
        "    \n",
        "    if path.is_file():\n",
        "        # Single file\n",
        "        if path.suffix.lower() in AUDIO_EXTENSIONS:\n",
        "            return [path]\n",
        "        else:\n",
        "            raise ValueError(f\"Not a supported audio format: {path.suffix}\")\n",
        "    else:\n",
        "        # Directory\n",
        "        audio_files = []\n",
        "        for ext in AUDIO_EXTENSIONS:\n",
        "            audio_files.extend(path.glob(f\"*{ext}\"))\n",
        "            audio_files.extend(path.glob(f\"*{ext.upper()}\"))\n",
        "        \n",
        "        if not audio_files:\n",
        "            raise ValueError(f\"No audio files found in: {path}\")\n",
        "        \n",
        "        return sorted(audio_files)\n",
        "\n",
        "# Get audio files\n",
        "try:\n",
        "    audio_files = get_audio_files(AUDIO_PATH)\n",
        "    console.print(f\"\\n[green]Found {len(audio_files)} audio file(s):[/green]\")\n",
        "    for f in audio_files[:5]:  # Show first 5\n",
        "        console.print(f\"  🎵 {f.name}\")\n",
        "    if len(audio_files) > 5:\n",
        "        console.print(f\"  ... and {len(audio_files) - 5} more\")\n",
        "except Exception as e:\n",
        "    console.print(f\"[red]Error: {e}[/red]\")\n",
        "    raise\n",
        "\n",
        "# Load the model\n",
        "console.print(f\"\\n[cyan]Loading Whisper model...[/cyan]\")\n",
        "model = load_whisper_model(MODEL_SIZE, force_cpu=FORCE_CPU)\n",
        "\n",
        "# Set output directory\n",
        "if OUTPUT_DIR:\n",
        "    output_path = Path(OUTPUT_DIR)\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "else:\n",
        "    output_path = None\n",
        "\n",
        "# Process each file\n",
        "console.print(f\"\\n[bold cyan]Starting transcription of {len(audio_files)} file(s)...[/bold cyan]\")\n",
        "\n",
        "total_start = time.time()\n",
        "results = []\n",
        "\n",
        "for i, audio_file in enumerate(audio_files):\n",
        "    console.print(f\"\\n[cyan]File {i+1}/{len(audio_files)}[/cyan]\")\n",
        "    \n",
        "    try:\n",
        "        result = transcribe_file(\n",
        "            audio_file=audio_file,\n",
        "            model=model,\n",
        "            language=LANGUAGE,\n",
        "            output_format=OUTPUT_FORMAT,\n",
        "            output_dir=output_path,\n",
        "            multilingual=MULTILINGUAL\n",
        "        )\n",
        "        results.append(result)\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Error transcribing {audio_file.name}: {e}[/red]\")\n",
        "        continue\n",
        "\n",
        "total_duration = time.time() - total_start\n",
        "\n",
        "# Summary\n",
        "console.print(\"\\n\" + \"=\"*60)\n",
        "console.print(Panel.fit(\n",
        "    f\"[bold green]✅ Transcription Complete![/bold green]\\n\\n\"\n",
        "    f\"Files processed: {len(results)}/{len(audio_files)}\\n\"\n",
        "    f\"Total time: {total_duration:.1f}s ({total_duration/60:.1f} min)\",\n",
        "    title=\"Session Summary\",\n",
        "    border_style=\"green\"\n",
        "))\n",
        "\n",
        "# Show performance stats\n",
        "if results:\n",
        "    total_audio = sum(r[\"audio_duration\"] for r in results)\n",
        "    total_process = sum(r[\"processing_time\"] for r in results)\n",
        "    avg_speed = total_audio / total_process if total_process > 0 else 0\n",
        "    \n",
        "    stats_table = Table(title=\"Performance Statistics\")\n",
        "    stats_table.add_column(\"Metric\", style=\"cyan\")\n",
        "    stats_table.add_column(\"Value\", style=\"yellow\")\n",
        "    \n",
        "    stats_table.add_row(\"Total Audio Duration\", f\"{total_audio:.1f}s ({total_audio/60:.1f} min)\")\n",
        "    stats_table.add_row(\"Total Processing Time\", f\"{total_process:.1f}s ({total_process/60:.1f} min)\")\n",
        "    stats_table.add_row(\"Average Speed\", f\"{avg_speed:.1f}x realtime\")\n",
        "    stats_table.add_row(\"Total Segments\", str(sum(r[\"segments\"] for r in results)))\n",
        "    \n",
        "    console.print(\"\\n\")\n",
        "    console.print(stats_table)\n",
        "\n",
        "print(\"\\n✨ All done! Check your output files in Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 📚 Usage Examples\n",
        "\n",
        "### Example 1: Transcribe a single file\n",
        "```python\n",
        "AUDIO_PATH = \"/content/drive/MyDrive/recordings/interview.mp3\"\n",
        "OUTPUT_FORMAT = \"txt\"\n",
        "```\n",
        "\n",
        "### Example 2: Transcribe all files in a folder with subtitles\n",
        "```python\n",
        "AUDIO_PATH = \"/content/drive/MyDrive/podcasts/\"\n",
        "OUTPUT_FORMAT = \"srt\"  # or \"all\" for all formats\n",
        "```\n",
        "\n",
        "### Example 3: Portuguese transcription with large model\n",
        "```python\n",
        "AUDIO_PATH = \"/content/drive/MyDrive/aula.wav\"\n",
        "MODEL_SIZE = \"large\"\n",
        "LANGUAGE = \"pt\"\n",
        "```\n",
        "\n",
        "### Example 4: Multilingual transcription (detect language changes)\n",
        "```python\n",
        "AUDIO_PATH = \"/content/drive/MyDrive/bilingual_meeting.mp4\"\n",
        "MULTILINGUAL = True\n",
        "LANGUAGE = None  # Auto-detect\n",
        "OUTPUT_FORMAT = \"all\"\n",
        "```\n",
        "\n",
        "## 💡 Tips\n",
        "\n",
        "1. **Model Selection**:\n",
        "   - `tiny`: Fastest but least accurate (good for quick drafts)\n",
        "   - `base`: Good balance of speed and accuracy (recommended)\n",
        "   - `large`: Best accuracy but slower (use for important content)\n",
        "\n",
        "2. **GPU Usage**:\n",
        "   - Colab's free GPU makes transcription 3-5x faster\n",
        "   - Check GPU availability in Runtime > Change runtime type\n",
        "\n",
        "3. **File Organization**:\n",
        "   - Keep audio files organized in folders by project\n",
        "   - Use OUTPUT_DIR to separate transcriptions from audio files\n",
        "\n",
        "4. **Language Detection**:\n",
        "   - Use `LANGUAGE = None` for auto-detection\n",
        "   - Use `MULTILINGUAL = True` for mixed-language content\n",
        "\n",
        "5. **Output Formats**:\n",
        "   - `txt`: Plain text (best for reading)\n",
        "   - `srt`: Subtitles with timestamps (for video editing)\n",
        "   - `vtt`: Web subtitles (for HTML5 video)\n",
        "   - `all`: Generate all formats at once\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Interactive file browser for Google Drive\n",
        "# Run this cell if you want to browse and select files interactively\n",
        "\n",
        "from google.colab import widgets\n",
        "import ipywidgets as ipw\n",
        "from IPython.display import display\n",
        "\n",
        "def list_audio_files_in_drive(root_path=\"/content/drive/MyDrive\", max_files=100):\n",
        "    \"\"\"List audio files in Google Drive.\"\"\"\n",
        "    audio_files = []\n",
        "    root = Path(root_path)\n",
        "    \n",
        "    if not root.exists():\n",
        "        print(f\"Path not found: {root}\")\n",
        "        return []\n",
        "    \n",
        "    # Search for audio files\n",
        "    for ext in AUDIO_EXTENSIONS:\n",
        "        audio_files.extend(list(root.rglob(f\"*{ext}\"))[:max_files])\n",
        "        if len(audio_files) >= max_files:\n",
        "            break\n",
        "    \n",
        "    return sorted(audio_files)[:max_files]\n",
        "\n",
        "# Find audio files\n",
        "print(\"🔍 Searching for audio files in your Google Drive...\")\n",
        "print(\"(This may take a moment for large drives)\\n\")\n",
        "\n",
        "audio_files_found = list_audio_files_in_drive()\n",
        "\n",
        "if audio_files_found:\n",
        "    print(f\"Found {len(audio_files_found)} audio files:\\n\")\n",
        "    \n",
        "    # Create dropdown widget\n",
        "    file_dropdown = ipw.Dropdown(\n",
        "        options=[(f.name, str(f)) for f in audio_files_found],\n",
        "        description='Select file:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=ipw.Layout(width='80%')\n",
        "    )\n",
        "    \n",
        "    # Model dropdown\n",
        "    model_dropdown = ipw.Dropdown(\n",
        "        options=['tiny', 'base', 'small', 'medium', 'large'],\n",
        "        value='base',\n",
        "        description='Model:',\n",
        "    )\n",
        "    \n",
        "    # Language dropdown\n",
        "    lang_dropdown = ipw.Dropdown(\n",
        "        options=[('Auto-detect', None), ('English', 'en'), ('Portuguese', 'pt')],\n",
        "        value=None,\n",
        "        description='Language:',\n",
        "    )\n",
        "    \n",
        "    # Format dropdown\n",
        "    format_dropdown = ipw.Dropdown(\n",
        "        options=['txt', 'srt', 'vtt', 'all'],\n",
        "        value='txt',\n",
        "        description='Format:',\n",
        "    )\n",
        "    \n",
        "    # Transcribe button\n",
        "    button = ipw.Button(\n",
        "        description='Transcribe Selected File',\n",
        "        button_style='success',\n",
        "        icon='play'\n",
        "    )\n",
        "    \n",
        "    output = ipw.Output()\n",
        "    \n",
        "    def on_button_click(b):\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            selected_file = Path(file_dropdown.value)\n",
        "            print(f\"Transcribing: {selected_file.name}\")\n",
        "            \n",
        "            # Load model if needed\n",
        "            model = load_whisper_model(model_dropdown.value)\n",
        "            \n",
        "            # Transcribe\n",
        "            result = transcribe_file(\n",
        "                audio_file=selected_file,\n",
        "                model=model,\n",
        "                language=lang_dropdown.value,\n",
        "                output_format=format_dropdown.value,\n",
        "                multilingual=False\n",
        "            )\n",
        "    \n",
        "    button.on_click(on_button_click)\n",
        "    \n",
        "    # Display widgets\n",
        "    display(file_dropdown)\n",
        "    display(ipw.HBox([model_dropdown, lang_dropdown, format_dropdown]))\n",
        "    display(button)\n",
        "    display(output)\n",
        "    \n",
        "else:\n",
        "    print(\"No audio files found in your Google Drive.\")\n",
        "    print(\"Make sure you have audio files in /content/drive/MyDrive/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 🔧 Troubleshooting\n",
        "\n",
        "### Common Issues:\n",
        "\n",
        "1. **\"No GPU detected\"**\n",
        "   - Go to Runtime → Change runtime type → GPU\n",
        "   - Select T4 GPU (free tier)\n",
        "   - Restart runtime\n",
        "\n",
        "2. **\"Audio file not found\"**\n",
        "   - Check the file path is correct\n",
        "   - Ensure Google Drive is mounted\n",
        "   - Use forward slashes (/) not backslashes\n",
        "\n",
        "3. **\"Out of memory\"**\n",
        "   - Use a smaller model (tiny or base)\n",
        "   - Process files one at a time\n",
        "   - Restart runtime to clear memory\n",
        "\n",
        "4. **\"Import error\"**\n",
        "   - Run the installation cell again\n",
        "   - Restart runtime after installation\n",
        "   - Check for any error messages during pip install\n",
        "\n",
        "5. **Slow transcription**\n",
        "   - Ensure GPU is enabled (check first cell)\n",
        "   - Use a smaller model for faster processing\n",
        "   - Check file size - very long audio files will take time\n",
        "\n",
        "### 📞 Need Help?\n",
        "\n",
        "- Check the [GitHub repository](https://github.com/gustavo-meilus/transcriber) for updates\n",
        "- Report issues with specific error messages\n",
        "- For Colab-specific issues, check [Colab FAQ](https://research.google.com/colaboratory/faq.html)\n",
        "\n",
        "---\n",
        "\n",
        "**Created by**: Gustavo Meilus  \n",
        "**License**: MIT\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}