{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ðŸŽ™ï¸ Audio Transcription with Google Drive Integration\n",
        "\n",
        "This notebook allows you to transcribe audio files stored in your Google Drive using the `transcript_pkg`.\n",
        "\n",
        "## Features:\n",
        "- ðŸ“ Transcribe single files or entire folders\n",
        "- ðŸŒ Support for multiple languages (English, Portuguese, Auto-detect)\n",
        "- ðŸ“ Multiple output formats (TXT, SRT, VTT)\n",
        "- ðŸš€ GPU acceleration support\n",
        "- ðŸ’¾ Save results directly to Google Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips and Best Practices\n",
        "\n",
        "### Model Selection Guide:\n",
        "- **tiny**: Fastest (39M parameters) - Good for quick drafts\n",
        "- **base**: Balanced (74M parameters) - Recommended for most use cases\n",
        "- **small**: Better accuracy (244M parameters) - Good for important content\n",
        "- **medium**: High accuracy (769M parameters) - For professional use\n",
        "- **large**: Best accuracy (1550M parameters) - When quality is critical\n",
        "\n",
        "### Performance Tips:\n",
        "1. **GPU Acceleration**: Google Colab provides free GPU access. Always check GPU is enabled: Runtime â†’ Change runtime type â†’ GPU\n",
        "2. **Batch Processing**: Process multiple files at once for efficiency\n",
        "3. **File Size**: For very long audio files (>1 hour), consider splitting them first\n",
        "\n",
        "### Language Settings:\n",
        "- Use `auto` for mixed-language content or when unsure\n",
        "- Use specific language codes (`en`, `pt`) for better accuracy when language is known\n",
        "- Enable `multilingual` mode for content with multiple languages\n",
        "\n",
        "### Output Formats:\n",
        "- **txt**: Plain text, best for reading and searching\n",
        "- **srt**: Subtitle format with timestamps, compatible with most video players\n",
        "- **vtt**: WebVTT format, ideal for web-based video players\n",
        "\n",
        "### Troubleshooting:\n",
        "- If transcription fails, check file format is supported\n",
        "- Ensure sufficient Google Drive storage space\n",
        "- For large batches, monitor Colab runtime limits\n",
        "- Clear Colab disk space if needed: `!rm -rf /content/*`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 1: Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"âœ… Google Drive mounted successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q faster-whisper rich tinytag scipy sounddevice numpy\n",
        "\n",
        "# Install ffmpeg for audio processing\n",
        "!apt-get -qq install -y ffmpeg\n",
        "\n",
        "print(\"âœ… All dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Setup transcript_pkg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup transcript_pkg by copying the actual files\n",
        "# You can either clone your repository or upload the transcript_pkg folder to Colab\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Option 1: If you have the transcript_pkg in your repository\n",
        "# !git clone https://github.com/yourusername/transcriber.git /content/transcriber\n",
        "\n",
        "# Option 2: Create a minimal version for Colab\n",
        "os.makedirs('/content/transcript_pkg', exist_ok=True)\n",
        "\n",
        "# Create __init__.py\n",
        "with open('/content/transcript_pkg/__init__.py', 'w') as f:\n",
        "    f.write('\"\"\"Audio transcription tools for live and file-based transcription.\"\"\"\\n\\n__version__ = \"0.1.0\"\\n')\n",
        "\n",
        "print(\"âœ… transcript_pkg directory created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simplified file_transcribe module for Google Colab\n",
        "file_transcribe_code = '''\"\"\"Simplified file transcription module for Google Colab.\"\"\"\n",
        "\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Optional, List, Dict, Tuple\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from faster_whisper import WhisperModel\n",
        "from rich.console import Console\n",
        "from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "\n",
        "console = Console()\n",
        "\n",
        "AUDIO_EXTENSIONS = {\n",
        "    \".mp3\", \".wav\", \".flac\", \".ogg\", \".m4a\", \".mp4\", \n",
        "    \".aac\", \".wma\", \".opus\", \".webm\", \".mkv\", \".avi\", \".mov\", \".m4v\"\n",
        "}\n",
        "\n",
        "LANGUAGE_MAP = {\n",
        "    \"en\": \"en\",\n",
        "    \"pt\": \"pt\", \n",
        "    \"auto\": None\n",
        "}\n",
        "\n",
        "def format_timestamp(seconds: float) -> str:\n",
        "    \"\"\"Convert seconds to timestamp format.\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = seconds % 60\n",
        "    return f\"{hours:02d}:{minutes:02d}:{secs:06.3f}\"\n",
        "\n",
        "def format_duration(seconds: float) -> str:\n",
        "    \"\"\"Format duration in human-readable format.\"\"\"\n",
        "    if seconds < 60:\n",
        "        return f\"{seconds:.1f}s\"\n",
        "    elif seconds < 3600:\n",
        "        return f\"{seconds/60:.1f}m\"\n",
        "    else:\n",
        "        return f\"{seconds/3600:.1f}h\"\n",
        "\n",
        "class StreamingTranscriptionWriter:\n",
        "    \"\"\"Handles streaming output of transcription data.\"\"\"\n",
        "    \n",
        "    def __init__(self, output_file: Path, format_type: str, multilingual: bool = False):\n",
        "        self.output_file = output_file\n",
        "        self.format_type = format_type\n",
        "        self.multilingual = multilingual\n",
        "        self.segment_count = 0\n",
        "        self.file_handle = None\n",
        "        self._initialize_file()\n",
        "    \n",
        "    def _initialize_file(self):\n",
        "        \"\"\"Initialize the output file with headers if needed.\"\"\"\n",
        "        self.output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        if self.format_type == \"txt\":\n",
        "            self.file_handle = open(self.output_file, \"w\", encoding=\"utf-8\")\n",
        "            if self.multilingual:\n",
        "                self.file_handle.write(\"[Multilingual transcription - language shown in brackets]\\\\n\\\\n\")\n",
        "        elif self.format_type == \"vtt\":\n",
        "            self.file_handle = open(self.output_file, \"w\", encoding=\"utf-8\")\n",
        "            self.file_handle.write(\"WEBVTT\\\\n\\\\n\")\n",
        "        elif self.format_type == \"srt\":\n",
        "            self.file_handle = open(self.output_file, \"w\", encoding=\"utf-8\")\n",
        "    \n",
        "    def write_segment(self, segment):\n",
        "        \"\"\"Write a single segment to the output file.\"\"\"\n",
        "        if not self.file_handle:\n",
        "            return\n",
        "        \n",
        "        self.segment_count += 1\n",
        "        \n",
        "        if self.format_type == \"txt\":\n",
        "            if self.multilingual and hasattr(segment, \"language\"):\n",
        "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\n\")\n",
        "            else:\n",
        "                self.file_handle.write(f\"{segment.text.strip()}\\\\n\")\n",
        "        \n",
        "        elif self.format_type == \"srt\":\n",
        "            self.file_handle.write(f\"{self.segment_count}\\\\n\")\n",
        "            start = format_timestamp(segment.start).replace(\".\", \",\")\n",
        "            end = format_timestamp(segment.end).replace(\".\", \",\")\n",
        "            self.file_handle.write(f\"{start} --> {end}\\\\n\")\n",
        "            if self.multilingual and hasattr(segment, \"language\"):\n",
        "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\n\\\\n\")\n",
        "            else:\n",
        "                self.file_handle.write(f\"{segment.text.strip()}\\\\n\\\\n\")\n",
        "        \n",
        "        elif self.format_type == \"vtt\":\n",
        "            start = format_timestamp(segment.start)\n",
        "            end = format_timestamp(segment.end)\n",
        "            self.file_handle.write(f\"{start} --> {end}\\\\n\")\n",
        "            if self.multilingual and hasattr(segment, \"language\"):\n",
        "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\n\\\\n\")\n",
        "            else:\n",
        "                self.file_handle.write(f\"{segment.text.strip()}\\\\n\\\\n\")\n",
        "        \n",
        "        self.file_handle.flush()\n",
        "    \n",
        "    def close(self):\n",
        "        \"\"\"Close the output file.\"\"\"\n",
        "        if self.file_handle:\n",
        "            self.file_handle.close()\n",
        "\n",
        "def detect_device_and_compute_type() -> Tuple[str, str]:\n",
        "    \"\"\"Detect if GPU is available and return appropriate device and compute type.\"\"\"\n",
        "    try:\n",
        "        import torch\n",
        "        if torch.cuda.is_available():\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            console.print(f\"[green]âœ“[/green] GPU detected: {gpu_name}\")\n",
        "            return \"cuda\", \"float16\"\n",
        "    except ImportError:\n",
        "        pass\n",
        "    \n",
        "    console.print(\"[yellow]â„¹[/yellow] Using CPU for transcription\")\n",
        "    return \"cpu\", \"int8\"\n",
        "\n",
        "def load_whisper_model_with_retry(model_size: str, device: str, compute_type: str, max_retries: int = 3):\n",
        "    \"\"\"Load Whisper model with retry logic for handling Hugging Face connectivity issues.\"\"\"\n",
        "    import time\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            console.print(f\"[cyan]Loading model (attempt {attempt + 1}/{max_retries})...[/cyan]\")\n",
        "            \n",
        "            # Try different loading strategies\n",
        "            try:\n",
        "                # First try: Normal loading with local_files_only=False\n",
        "                model = WhisperModel(\n",
        "                    model_size, \n",
        "                    device=device, \n",
        "                    compute_type=compute_type,\n",
        "                    local_files_only=False\n",
        "                )\n",
        "                return model\n",
        "            except Exception as e1:\n",
        "                console.print(f\"[yellow]Standard loading failed: {str(e1)[:100]}...[/yellow]\")\n",
        "                \n",
        "                # Second try: Download path explicitly\n",
        "                try:\n",
        "                    # Set environment variable to avoid the HF token warning\n",
        "                    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "                    \n",
        "                    # Try with download_root\n",
        "                    download_root = \"/content/whisper_models\"\n",
        "                    os.makedirs(download_root, exist_ok=True)\n",
        "                    \n",
        "                    model = WhisperModel(\n",
        "                        model_size,\n",
        "                        device=device,\n",
        "                        compute_type=compute_type,\n",
        "                        download_root=download_root\n",
        "                    )\n",
        "                    return model\n",
        "                except Exception as e2:\n",
        "                    console.print(f\"[yellow]Download root method failed: {str(e2)[:100]}...[/yellow]\")\n",
        "                    \n",
        "                    # Third try: Use alternative loading\n",
        "                    if attempt < max_retries - 1:\n",
        "                        wait_time = (attempt + 1) * 5\n",
        "                        console.print(f\"[yellow]Waiting {wait_time} seconds before retry...[/yellow]\")\n",
        "                        time.sleep(wait_time)\n",
        "                    else:\n",
        "                        raise Exception(f\"Failed to load model after {max_retries} attempts\")\n",
        "                        \n",
        "        except Exception as e:\n",
        "            if attempt == max_retries - 1:\n",
        "                console.print(f\"[red]Failed to load model: {e}[/red]\")\n",
        "                console.print(\"[yellow]Troubleshooting tips:[/yellow]\")\n",
        "                console.print(\"1. Try restarting the Colab runtime\")\n",
        "                console.print(\"2. Check your internet connection\")\n",
        "                console.print(\"3. Try a different model size (e.g., 'tiny' or 'small')\")\n",
        "                console.print(\"4. Clear Colab cache: !rm -rf /root/.cache/huggingface\")\n",
        "                raise\n",
        "    \n",
        "    return None\n",
        "\n",
        "def transcribe_file(\n",
        "    audio_file: Path,\n",
        "    model: WhisperModel,\n",
        "    output_dir: Path,\n",
        "    language: str = \"auto\",\n",
        "    output_format: str = \"txt\",\n",
        "    multilingual: bool = False\n",
        ") -> Dict:\n",
        "    \"\"\"Transcribe a single audio file.\"\"\"\n",
        "    \n",
        "    # Prepare output file\n",
        "    output_file = output_dir / f\"{audio_file.stem}.{output_format}\"\n",
        "    \n",
        "    # Create writer\n",
        "    writer = StreamingTranscriptionWriter(output_file, output_format, multilingual)\n",
        "    \n",
        "    # Start transcription\n",
        "    console.print(f\"[cyan]Processing:[/cyan] {audio_file.name}\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Transcribe\n",
        "        segments, info = model.transcribe(\n",
        "            str(audio_file),\n",
        "            language=LANGUAGE_MAP.get(language),\n",
        "            beam_size=5,\n",
        "            vad_filter=True,\n",
        "            vad_parameters=dict(min_silence_duration_ms=500),\n",
        "            multilingual=multilingual\n",
        "        )\n",
        "        \n",
        "        # Process segments\n",
        "        segment_count = 0\n",
        "        for segment in segments:\n",
        "            writer.write_segment(segment)\n",
        "            segment_count += 1\n",
        "        \n",
        "        # Close writer\n",
        "        writer.close()\n",
        "        \n",
        "        # Calculate stats\n",
        "        process_time = time.time() - start_time\n",
        "        speed = info.duration / process_time if process_time > 0 else 0\n",
        "        \n",
        "        console.print(\n",
        "            f\"[green]âœ“[/green] {audio_file.name} \"\n",
        "            f\"[dim]({info.duration:.1f}s @ {speed:.1f}x speed, {segment_count} segments)[/dim]\"\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"file\": audio_file.name,\n",
        "            \"duration\": info.duration,\n",
        "            \"segments\": segment_count,\n",
        "            \"process_time\": process_time,\n",
        "            \"speed\": speed,\n",
        "            \"output_file\": str(output_file),\n",
        "            \"detected_language\": info.language if language == \"auto\" else language\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        writer.close()\n",
        "        console.print(f\"[red]âœ—[/red] Error processing {audio_file.name}: {e}\")\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"file\": audio_file.name,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "def find_audio_files(input_path: Path) -> List[Path]:\n",
        "    \"\"\"Find all audio files in the given path.\"\"\"\n",
        "    audio_files = []\n",
        "    \n",
        "    if input_path.is_file():\n",
        "        if input_path.suffix.lower() in AUDIO_EXTENSIONS:\n",
        "            audio_files.append(input_path)\n",
        "    else:\n",
        "        for ext in AUDIO_EXTENSIONS:\n",
        "            audio_files.extend(input_path.glob(f\"*{ext}\"))\n",
        "            audio_files.extend(input_path.glob(f\"*{ext.upper()}\"))\n",
        "    \n",
        "    return sorted(audio_files)\n",
        "\n",
        "def transcribe_folder(\n",
        "    input_path: Path,\n",
        "    output_path: Path,\n",
        "    model_size: str = \"base\",\n",
        "    language: str = \"auto\",\n",
        "    output_format: str = \"txt\",\n",
        "    multilingual: bool = False\n",
        ") -> List[Dict]:\n",
        "    \"\"\"Transcribe all audio files in a folder.\"\"\"\n",
        "    \n",
        "    # Find audio files\n",
        "    audio_files = find_audio_files(input_path)\n",
        "    \n",
        "    if not audio_files:\n",
        "        console.print(\"[red]No audio files found![/red]\")\n",
        "        return []\n",
        "    \n",
        "    console.print(f\"[green]Found {len(audio_files)} audio files[/green]\")\n",
        "    \n",
        "    # Create output directory\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Load model with retry logic\n",
        "    device, compute_type = detect_device_and_compute_type()\n",
        "    console.print(f\"[cyan]Loading Whisper {model_size} model...[/cyan]\")\n",
        "    \n",
        "    try:\n",
        "        with console.status(\"[bold cyan]Loading model...[/bold cyan]\"):\n",
        "            model = load_whisper_model_with_retry(model_size, device=device, compute_type=compute_type)\n",
        "        \n",
        "        console.print(f\"[green]âœ“[/green] Model loaded successfully!\")\n",
        "    except Exception as e:\n",
        "        console.print(f\"[red]Error loading model: {e}[/red]\")\n",
        "        console.print(\"\\\\n[yellow]Alternative solution:[/yellow]\")\n",
        "        console.print(\"Try running this command first to clear cache:\")\n",
        "        console.print(\"[cyan]!rm -rf /root/.cache/huggingface[/cyan]\")\n",
        "        console.print(\"Then restart the runtime and try again.\")\n",
        "        return []\n",
        "    \n",
        "    # Process files\n",
        "    results = []\n",
        "    with Progress(\n",
        "        SpinnerColumn(),\n",
        "        TextColumn(\"[bold blue]{task.description}\"),\n",
        "        BarColumn(),\n",
        "        TaskProgressColumn(),\n",
        "        console=console\n",
        "    ) as progress:\n",
        "        task = progress.add_task(\"Transcribing files...\", total=len(audio_files))\n",
        "        \n",
        "        for audio_file in audio_files:\n",
        "            result = transcribe_file(\n",
        "                audio_file, model, output_path, \n",
        "                language, output_format, multilingual\n",
        "            )\n",
        "            results.append(result)\n",
        "            progress.advance(task)\n",
        "    \n",
        "    return results\n",
        "\n",
        "def display_results_summary(results: List[Dict]):\n",
        "    \"\"\"Display a summary of transcription results.\"\"\"\n",
        "    if not results:\n",
        "        return\n",
        "    \n",
        "    # Create summary table\n",
        "    table = Table(title=\"ðŸ“Š Transcription Results\", show_header=True, header_style=\"bold cyan\")\n",
        "    table.add_column(\"File\", style=\"cyan\", width=30)\n",
        "    table.add_column(\"Status\", style=\"green\")\n",
        "    table.add_column(\"Duration\", justify=\"right\")\n",
        "    table.add_column(\"Segments\", justify=\"right\")\n",
        "    table.add_column(\"Speed\", justify=\"right\")\n",
        "    \n",
        "    successful = 0\n",
        "    failed = 0\n",
        "    total_duration = 0\n",
        "    total_time = 0\n",
        "    \n",
        "    for result in results:\n",
        "        if result[\"success\"]:\n",
        "            successful += 1\n",
        "            total_duration += result[\"duration\"]\n",
        "            total_time += result[\"process_time\"]\n",
        "            \n",
        "            table.add_row(\n",
        "                result[\"file\"][:30] + \"...\" if len(result[\"file\"]) > 30 else result[\"file\"],\n",
        "                \"âœ… Success\",\n",
        "                format_duration(result[\"duration\"]),\n",
        "                str(result[\"segments\"]),\n",
        "                f\"{result['speed']:.1f}x\"\n",
        "            )\n",
        "        else:\n",
        "            failed += 1\n",
        "            error_msg = str(result[\"error\"])[:20] + \"...\" if len(str(result[\"error\"])) > 20 else str(result[\"error\"])\n",
        "            table.add_row(\n",
        "                result[\"file\"][:30] + \"...\" if len(result[\"file\"]) > 30 else result[\"file\"],\n",
        "                f\"âŒ {error_msg}\",\n",
        "                \"-\",\n",
        "                \"-\",\n",
        "                \"-\"\n",
        "            )\n",
        "    \n",
        "    console.print(\"\\\\n\")\n",
        "    console.print(table)\n",
        "    \n",
        "    # Summary statistics\n",
        "    if successful > 0:\n",
        "        avg_speed = total_duration / total_time if total_time > 0 else 0\n",
        "        console.print(\"\\\\n\")\n",
        "        console.print(Panel(\n",
        "            f\"[bold]Summary:[/bold]\\\\n\\\\n\"\n",
        "            f\"âœ… Successful: {successful} files\\\\n\"\n",
        "            f\"âŒ Failed: {failed} files\\\\n\"\n",
        "            f\"â±ï¸  Total audio: {format_duration(total_duration)}\\\\n\"\n",
        "            f\"âš¡ Processing time: {format_duration(total_time)}\\\\n\"\n",
        "            f\"ðŸš€ Average speed: {avg_speed:.1f}x realtime\",\n",
        "            title=\"[bold green]Transcription Complete![/bold green]\",\n",
        "            border_style=\"green\"\n",
        "        ))\n",
        "'''\n",
        "\n",
        "with open('/content/transcript_pkg/file_transcribe.py', 'w') as f:\n",
        "    f.write(file_transcribe_code)\n",
        "\n",
        "print(\"âœ… file_transcribe.py created with improved model loading!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### âš ï¸ Troubleshooting: Model Loading Issues\n",
        "\n",
        "If you encounter a **\"502 Bad Gateway\"** or similar error when loading the model, this is usually due to Hugging Face connectivity issues. The notebook now includes retry logic to handle this automatically. However, if the issue persists:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clear Hugging Face cache if you encounter model loading errors\n",
        "# Uncomment and run if needed:\n",
        "# !rm -rf /root/.cache/huggingface\n",
        "# !rm -rf /content/whisper_models\n",
        "\n",
        "# After running this, restart the runtime: Runtime â†’ Restart runtime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Configure Transcription Settings\n",
        "\n",
        "Modify the parameters below according to your needs:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration parameters - MODIFY THESE AS NEEDED\n",
        "\n",
        "# Input path in Google Drive (can be a file or folder)\n",
        "INPUT_PATH = \"/content/drive/MyDrive/AudioFiles\"  # @param {type:\"string\"}\n",
        "\n",
        "# Output path in Google Drive  \n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Transcriptions\"  # @param {type:\"string\"}\n",
        "\n",
        "# Model size: tiny, base, small, medium, large\n",
        "MODEL_SIZE = \"base\"  # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
        "\n",
        "# Language: en (English), pt (Portuguese), auto (auto-detect)\n",
        "LANGUAGE = \"auto\"  # @param [\"auto\", \"en\", \"pt\"]\n",
        "\n",
        "# Output format: txt, srt, vtt\n",
        "OUTPUT_FORMAT = \"txt\"  # @param [\"txt\", \"srt\", \"vtt\"]\n",
        "\n",
        "# Enable multilingual mode (shows language for each segment)\n",
        "MULTILINGUAL = False  # @param {type:\"boolean\"}\n",
        "\n",
        "print(\"ðŸ“‹ Configuration:\")\n",
        "print(f\"  Input: {INPUT_PATH}\")\n",
        "print(f\"  Output: {OUTPUT_PATH}\")\n",
        "print(f\"  Model: {MODEL_SIZE}\")\n",
        "print(f\"  Language: {LANGUAGE}\")\n",
        "print(f\"  Format: {OUTPUT_FORMAT}\")\n",
        "print(f\"  Multilingual: {MULTILINGUAL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Run Transcription\n",
        "\n",
        "Execute the cell below to start the transcription process:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append('/content')\n",
        "\n",
        "from transcript_pkg.file_transcribe import transcribe_folder, display_results_summary\n",
        "from rich.console import Console\n",
        "from rich.panel import Panel\n",
        "\n",
        "console = Console()\n",
        "\n",
        "# Convert paths\n",
        "input_path = Path(INPUT_PATH)\n",
        "output_path = Path(OUTPUT_PATH)\n",
        "\n",
        "# Check if input exists\n",
        "if not input_path.exists():\n",
        "    console.print(f\"[red]Error: Input path does not exist: {INPUT_PATH}[/red]\")\n",
        "    console.print(\"[yellow]Please check your INPUT_PATH and ensure the folder/file exists in your Google Drive.[/yellow]\")\n",
        "else:\n",
        "    # Run transcription\n",
        "    console.print(Panel(\n",
        "        \"[bold green]Starting Transcription Process[/bold green]\\n\\n\"\n",
        "        \"This may take a while depending on the size and number of files.\\n\"\n",
        "        \"The process will use GPU acceleration if available.\",\n",
        "        title=\"ðŸŽ™ï¸ Transcription\",\n",
        "        border_style=\"green\"\n",
        "    ))\n",
        "    \n",
        "    results = transcribe_folder(\n",
        "        input_path=input_path,\n",
        "        output_path=output_path,\n",
        "        model_size=MODEL_SIZE,\n",
        "        language=LANGUAGE,\n",
        "        output_format=OUTPUT_FORMAT,\n",
        "        multilingual=MULTILINGUAL\n",
        "    )\n",
        "    \n",
        "    # Display results summary\n",
        "    if results:\n",
        "        display_results_summary(results)\n",
        "        \n",
        "        # Show output location\n",
        "        console.print(f\"\\nðŸ“ [bold cyan]Output files saved to:[/bold cyan] {output_path}\")\n",
        "        console.print(\"[dim]You can find your transcriptions in the specified Google Drive folder.[/dim]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 6: View Transcription Files\n",
        "\n",
        "List and preview the transcribed files:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all transcription files created\n",
        "import os\n",
        "from rich.table import Table\n",
        "\n",
        "if output_path.exists():\n",
        "    files = list(output_path.glob(f\"*.{OUTPUT_FORMAT}\"))\n",
        "    \n",
        "    if files:\n",
        "        # Create a table to display files\n",
        "        table = Table(title=f\"ðŸ“„ Transcription Files ({len(files)} total)\", show_header=True)\n",
        "        table.add_column(\"File Name\", style=\"cyan\")\n",
        "        table.add_column(\"Size\", justify=\"right\", style=\"yellow\")\n",
        "        table.add_column(\"Path\", style=\"dim\")\n",
        "        \n",
        "        for file in sorted(files):\n",
        "            size_kb = os.path.getsize(file) / 1024\n",
        "            table.add_row(\n",
        "                file.name,\n",
        "                f\"{size_kb:.1f} KB\",\n",
        "                str(file.relative_to(Path(\"/content/drive\")))\n",
        "            )\n",
        "        \n",
        "        console.print(table)\n",
        "    else:\n",
        "        console.print(\"[yellow]No transcription files found in the output directory.[/yellow]\")\n",
        "else:\n",
        "    console.print(\"[red]Output directory does not exist.[/red]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 7: Preview a Transcription\n",
        "\n",
        "Preview the content of the first transcription file:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview a transcription file\n",
        "if output_path.exists():\n",
        "    files = list(output_path.glob(f\"*.{OUTPUT_FORMAT}\"))\n",
        "    \n",
        "    if files:\n",
        "        # Let user select which file to preview\n",
        "        console.print(f\"\\n[cyan]Found {len(files)} transcription file(s). Showing preview of the first one.[/cyan]\")\n",
        "        \n",
        "        # Get the first file\n",
        "        preview_file = sorted(files)[0]\n",
        "        \n",
        "        console.print(f\"\\n[bold]File: {preview_file.name}[/bold]\\n\")\n",
        "        \n",
        "        # Read and display content (limit to first 1000 characters for preview)\n",
        "        try:\n",
        "            with open(preview_file, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "                preview_length = 1000\n",
        "                \n",
        "                if len(content) > preview_length:\n",
        "                    preview = content[:preview_length] + \"\\n\\n[... truncated for preview ...]\"\n",
        "                else:\n",
        "                    preview = content\n",
        "                \n",
        "                console.print(Panel(\n",
        "                    preview,\n",
        "                    title=f\"ðŸ“„ {preview_file.name}\",\n",
        "                    border_style=\"blue\",\n",
        "                    padding=(1, 2)\n",
        "                ))\n",
        "                \n",
        "                console.print(f\"\\n[dim]Full file location: {preview_file}[/dim]\")\n",
        "                console.print(f\"[dim]Total content length: {len(content)} characters[/dim]\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            console.print(f\"[red]Error reading file: {e}[/red]\")\n",
        "    else:\n",
        "        console.print(\"[yellow]No transcription files found to preview.[/yellow]\")\n",
        "else:\n",
        "    console.print(\"[red]Output directory does not exist.[/red]\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
