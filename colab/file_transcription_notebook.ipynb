{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# ðŸŽ™ï¸ Google Colab Audio Transcription Notebook\n",
    "\n",
    "This notebook allows you to transcribe audio/video files using OpenAI Whisper directly in Google Colab with GPU acceleration. Features include:\n",
    "\n",
    "- ðŸš€ **GPU acceleration** for faster processing\n",
    "- ðŸ“ **Batch processing** of multiple files\n",
    "- ðŸ’¾ **Direct Google Drive integration**\n",
    "- ðŸ”„ **Automatic resume** if interrupted\n",
    "- ðŸ“Š **Segment-by-segment progress tracking** with real-time ETA\n",
    "- â° **Connection keepalive** for long transcriptions\n",
    "- ðŸŽ¯ **Multiple output formats** (TXT, SRT, VTT)\n",
    "- ðŸŒ **Multilingual support** with language detection\n",
    "- ðŸ“¦ **Automatic chunking** for large audio files\n",
    "- ðŸ”§ **Built-in error recovery and retry logic**\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Follow the steps below to transcribe your audio files:\n",
    "\n",
    "1. **Mount Google Drive** - Connect your Drive to access files\n",
    "2. **Install Dependencies** - Set up required packages\n",
    "3. **Configure Settings** - Choose model, language, and output format\n",
    "4. **Run Transcription** - Process your files with progress tracking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Mount Google Drive\n",
    "\n",
    "First, let's mount your Google Drive to access audio files and save transcriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ… Google Drive mounted successfully!\")\n",
    "print(\"Your files are accessible at: /content/drive/MyDrive/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Install Dependencies\n",
    "\n",
    "Now let's install the required packages. This will install faster-whisper and other dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q faster-whisper rich tinytag\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Set up the Transcription Module\n",
    "\n",
    "This cell creates the enhanced transcription module with segment-based progress tracking and connection keepalive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the enhanced file_transcribe.py module with all features\n",
    "file_transcribe_code = '''#!/usr/bin/env python3\n",
    "\"\"\"Enhanced file transcription module with segment-based progress and keepalive for Colab.\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import gc\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "from rich.console import Console\n",
    "from rich.progress import (\n",
    "    Progress, BarColumn, TaskProgressColumn, \n",
    "    TimeElapsedColumn, SpinnerColumn, TextColumn, ProgressColumn\n",
    ")\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich import print as rprint\n",
    "from tinytag import TinyTag\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Supported audio/video extensions\n",
    "AUDIO_EXTENSIONS = {\n",
    "    \".mp3\", \".wav\", \".flac\", \".m4a\", \".aac\", \".ogg\", \".opus\", \".wma\",\n",
    "    \".mp4\", \".avi\", \".mkv\", \".mov\", \".webm\", \".m4v\", \".flv\", \".wmv\"\n",
    "}\n",
    "\n",
    "# Language mapping\n",
    "LANGUAGE_MAP = {\n",
    "    \"auto\": None,\n",
    "    \"en\": \"en\",\n",
    "    \"pt\": \"pt\"\n",
    "}\n",
    "\n",
    "class RemainingAudioDurationColumn(ProgressColumn):\n",
    "    \"\"\"Column showing estimated time remaining based on audio processing rate.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.task_etas = {}\n",
    "    \n",
    "    def set_eta(self, task_id, eta_seconds):\n",
    "        \"\"\"Set the ETA for a specific task.\"\"\"\n",
    "        self.task_etas[task_id] = eta_seconds\n",
    "    \n",
    "    def render(self, task):\n",
    "        \"\"\"Render the remaining time.\"\"\"\n",
    "        eta = self.task_etas.get(task.id, 0)\n",
    "        if eta > 0:\n",
    "            hours, remainder = divmod(int(eta), 3600)\n",
    "            minutes, seconds = divmod(remainder, 60)\n",
    "            if hours > 0:\n",
    "                return f\"ETA: {hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "            else:\n",
    "                return f\"ETA: {minutes:02d}:{seconds:02d}\"\n",
    "        return \"ETA: --:--\"\n",
    "\n",
    "class ColabKeepalive:\n",
    "    \"\"\"Keeps Colab connection alive during long-running operations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.running = False\n",
    "        self.thread = None\n",
    "        self.last_status = \"\"\n",
    "        self.update_count = 0\n",
    "    \n",
    "    def _keep_alive(self):\n",
    "        \"\"\"Background thread that updates periodically.\"\"\"\n",
    "        while self.running:\n",
    "            # Create a hidden div with current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            self.update_count += 1\n",
    "            \n",
    "            # Use HTML comment to avoid display conflicts\n",
    "            from IPython.display import HTML, display\n",
    "            display(HTML(f\"<!-- Keepalive pulse {self.update_count} at {timestamp} -->\"))\n",
    "            \n",
    "            # Sleep for 20 seconds between pulses\n",
    "            time.sleep(20)\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Start the keepalive thread.\"\"\"\n",
    "        if not self.running:\n",
    "            self.running = True\n",
    "            self.thread = threading.Thread(target=self._keep_alive, daemon=True)\n",
    "            self.thread.start()\n",
    "    \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the keepalive thread.\"\"\"\n",
    "        self.running = False\n",
    "        if self.thread:\n",
    "            self.thread.join(timeout=1)\n",
    "    \n",
    "    def update_status(self, status: str):\n",
    "        \"\"\"Update the current status (for logging purposes).\"\"\"\n",
    "        self.last_status = status\n",
    "    \n",
    "    def pulse(self):\n",
    "        \"\"\"Manual pulse (does nothing if thread is running).\"\"\"\n",
    "        pass  # The thread handles everything\n",
    "\n",
    "class TranscriptionCheckpoint:\n",
    "    \"\"\"Manages checkpoint files for resuming interrupted transcriptions.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir: Path):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.checkpoint_file = checkpoint_dir / \"transcription_checkpoint.json\"\n",
    "        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.state = {\n",
    "            \"files_completed\": [],\n",
    "            \"current_file\": None,\n",
    "            \"current_position\": 0,\n",
    "            \"segments\": [],\n",
    "            \"timestamp\": None\n",
    "        }\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"Save current checkpoint state.\"\"\"\n",
    "        self.state[\"timestamp\"] = datetime.now().isoformat()\n",
    "        with open(self.checkpoint_file, 'w') as f:\n",
    "            json.dump(self.state, f, indent=2)\n",
    "    \n",
    "    def load(self) -> bool:\n",
    "        \"\"\"Load checkpoint if exists.\"\"\"\n",
    "        if self.checkpoint_file.exists():\n",
    "            try:\n",
    "                with open(self.checkpoint_file, 'r') as f:\n",
    "                    self.state = json.load(f)\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "        return False\n",
    "    \n",
    "    def set_current_file(self, filename: str):\n",
    "        \"\"\"Set the file currently being processed.\"\"\"\n",
    "        self.state[\"current_file\"] = filename\n",
    "        self.state[\"current_position\"] = 0\n",
    "        self.state[\"segments\"] = []\n",
    "    \n",
    "    def update_progress(self, segment: Dict, position: float):\n",
    "        \"\"\"Update progress for current file.\"\"\"\n",
    "        self.state[\"segments\"].append(segment)\n",
    "        self.state[\"current_position\"] = position\n",
    "    \n",
    "    def mark_file_complete(self, filename: str):\n",
    "        \"\"\"Mark a file as completed.\"\"\"\n",
    "        if filename not in self.state[\"files_completed\"]:\n",
    "            self.state[\"files_completed\"].append(filename)\n",
    "        if self.state[\"current_file\"] == filename:\n",
    "            self.state[\"current_file\"] = None\n",
    "            self.state[\"current_position\"] = 0\n",
    "            self.state[\"segments\"] = []\n",
    "        self.save()\n",
    "    \n",
    "    def get_resume_info(self) -> Dict:\n",
    "        \"\"\"Get information for resuming transcription.\"\"\"\n",
    "        return {\n",
    "            \"completed_files\": self.state[\"files_completed\"],\n",
    "            \"current_file\": self.state[\"current_file\"],\n",
    "            \"current_position\": self.state[\"current_position\"]\n",
    "        }\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear checkpoint data.\"\"\"\n",
    "        if self.checkpoint_file.exists():\n",
    "            self.checkpoint_file.unlink()\n",
    "        self.state = {\n",
    "            \"files_completed\": [],\n",
    "            \"current_file\": None,\n",
    "            \"current_position\": 0,\n",
    "            \"segments\": [],\n",
    "            \"timestamp\": None\n",
    "        }\n",
    "\n",
    "def format_duration(seconds: float) -> str:\n",
    "    \"\"\"Format duration in seconds to human-readable format.\"\"\"\n",
    "    hours, remainder = divmod(int(seconds), 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    if hours > 0:\n",
    "        return f\"{hours}h {minutes}m {seconds}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}m {seconds}s\"\n",
    "    else:\n",
    "        return f\"{seconds}s\"\n",
    "\n",
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Format timestamp for subtitle files.\"\"\"\n",
    "    hours, remainder = divmod(int(seconds), 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    milliseconds = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}.{milliseconds:03d}\"\n",
    "\n",
    "def get_audio_duration(file_path: Path) -> float:\n",
    "    \"\"\"Get audio duration using tinytag.\"\"\"\n",
    "    try:\n",
    "        tag = TinyTag.get(str(file_path))\n",
    "        return tag.duration or 0\n",
    "    except Exception as e:\n",
    "        console.print(f\"[yellow]Warning: Could not get duration for {file_path.name}: {e}[/yellow]\")\n",
    "        return 0\n",
    "\n",
    "class StreamingTranscriptionWriter:\n",
    "    \"\"\"Writes transcription output in streaming fashion.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_file: Path, format_type: str = \"txt\", multilingual: bool = False):\n",
    "        self.output_file = output_file\n",
    "        self.format_type = format_type\n",
    "        self.multilingual = multilingual\n",
    "        self.file_handle = None\n",
    "        self.segment_count = 0\n",
    "        \n",
    "        # Open file for writing\n",
    "        self.file_handle = open(output_file, 'w', encoding='utf-8')\n",
    "        \n",
    "        # Write headers if needed\n",
    "        if format_type == \"vtt\":\n",
    "            self.file_handle.write(\"WEBVTT\\\\n\\\\n\")\n",
    "    \n",
    "    def write_segment(self, segment):\n",
    "        \"\"\"Write a single segment to the output file.\"\"\"\n",
    "        self.segment_count += 1\n",
    "        \n",
    "        if self.format_type == \"txt\":\n",
    "            if self.multilingual and hasattr(segment, \"language\"):\n",
    "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\n\")\n",
    "            else:\n",
    "                self.file_handle.write(f\"{segment.text.strip()}\\\\n\")\n",
    "        \n",
    "        elif self.format_type == \"srt\":\n",
    "            self.file_handle.write(f\"{self.segment_count}\\\\n\")\n",
    "            start = format_timestamp(segment.start).replace(\".\", \",\")\n",
    "            end = format_timestamp(segment.end).replace(\".\", \",\")\n",
    "            self.file_handle.write(f\"{start} --> {end}\\\\n\")\n",
    "            if self.multilingual and hasattr(segment, \"language\"):\n",
    "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\n\\\\n\")\n",
    "            else:\n",
    "                self.file_handle.write(f\"{segment.text.strip()}\\\\n\\\\n\")\n",
    "        \n",
    "        elif self.format_type == \"vtt\":\n",
    "            start = format_timestamp(segment.start)\n",
    "            end = format_timestamp(segment.end)\n",
    "            self.file_handle.write(f\"{start} --> {end}\\\\n\")\n",
    "            if self.multilingual and hasattr(segment, \"language\"):\n",
    "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\n\\\\n\")\n",
    "            else:\n",
    "                self.file_handle.write(f\"{segment.text.strip()}\\\\n\\\\n\")\n",
    "        \n",
    "        self.file_handle.flush()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the output file.\"\"\"\n",
    "        if self.file_handle:\n",
    "            self.file_handle.close()\n",
    "\n",
    "def detect_device_and_compute_type() -> Tuple[str, str]:\n",
    "    \"\"\"Detect if GPU is available and return appropriate device and compute type.\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            console.print(f\"[green]âœ“[/green] GPU detected: {gpu_name}\")\n",
    "            return \"cuda\", \"float16\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    console.print(\"[yellow]â„¹[/yellow] Using CPU for transcription\")\n",
    "    return \"cpu\", \"int8\"\n",
    "\n",
    "def load_whisper_model_with_retry(model_size: str, device: str, compute_type: str, max_retries: int = 3):\n",
    "    \"\"\"Load Whisper model with retry logic for handling Hugging Face connectivity issues.\"\"\"\n",
    "    import time\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            console.print(f\"[cyan]Loading model (attempt {attempt + 1}/{max_retries})...[/cyan]\")\n",
    "            \n",
    "            # Try different loading strategies\n",
    "            try:\n",
    "                # First try: Normal loading with local_files_only=False\n",
    "                model = WhisperModel(\n",
    "                    model_size, \n",
    "                    device=device, \n",
    "                    compute_type=compute_type,\n",
    "                    local_files_only=False\n",
    "                )\n",
    "                return model\n",
    "            except Exception as e1:\n",
    "                console.print(f\"[yellow]Standard loading failed: {str(e1)[:100]}...[/yellow]\")\n",
    "                \n",
    "                # Second try: Download path explicitly\n",
    "                try:\n",
    "                    # Set environment variable to avoid the HF token warning\n",
    "                    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "                    \n",
    "                    # Try with download_root\n",
    "                    download_root = \"/content/whisper_models\"\n",
    "                    os.makedirs(download_root, exist_ok=True)\n",
    "                    \n",
    "                    model = WhisperModel(\n",
    "                        model_size,\n",
    "                        device=device,\n",
    "                        compute_type=compute_type,\n",
    "                        download_root=download_root\n",
    "                    )\n",
    "                    return model\n",
    "                except Exception as e2:\n",
    "                    console.print(f\"[yellow]Download root method failed: {str(e2)[:100]}...[/yellow]\")\n",
    "                    \n",
    "                    # Third try: Use alternative loading\n",
    "                    if attempt < max_retries - 1:\n",
    "                        wait_time = (attempt + 1) * 5\n",
    "                        console.print(f\"[yellow]Waiting {wait_time} seconds before retry...[/yellow]\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        raise Exception(f\"Failed to load model after {max_retries} attempts\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                console.print(f\"[red]Failed to load model: {e}[/red]\")\n",
    "                console.print(\"[yellow]Troubleshooting tips:[/yellow]\")\n",
    "                console.print(\"1. Try restarting the Colab runtime\")\n",
    "                console.print(\"2. Check your internet connection\")\n",
    "                console.print(\"3. Try a different model size (e.g., 'tiny' or 'small')\")\n",
    "                console.print(\"4. Clear Colab cache: !rm -rf /root/.cache/huggingface\")\n",
    "                raise\n",
    "    \n",
    "    return None\n",
    "\n",
    "def transcribe_file_with_progress(\n",
    "    audio_file: Path,\n",
    "    model: WhisperModel,\n",
    "    output_dir: Path,\n",
    "    language: str = \"auto\",\n",
    "    output_format: str = \"txt\",\n",
    "    multilingual: bool = False,\n",
    "    keepalive: Optional[ColabKeepalive] = None,\n",
    "    progress: Optional[Progress] = None,\n",
    "    task_id: Optional[int] = None,\n",
    "    eta_column: Optional[RemainingAudioDurationColumn] = None,\n",
    "    checkpoint: Optional[TranscriptionCheckpoint] = None,\n",
    "    resume_position: float = 0,\n",
    "    chunk_large_files: bool = True,\n",
    "    chunk_duration: int = 600,  # 10 minutes\n",
    "    chunk_threshold: int = 900  # 15 minutes\n",
    ") -> Dict:\n",
    "    \"\"\"Transcribe a single audio file with segment-based progress tracking and chunking support.\"\"\"\n",
    "    \n",
    "    # Get audio duration\n",
    "    audio_duration = get_audio_duration(audio_file)\n",
    "    \n",
    "    # Check if file needs chunking\n",
    "    needs_chunking = chunk_large_files and chunk_duration > 0 and audio_duration > chunk_threshold\n",
    "    \n",
    "    if needs_chunking:\n",
    "        console.print(Panel(\n",
    "            f\"[yellow]Large file detected: {audio_file.name}[/yellow]\\\\n\"\n",
    "            f\"Duration: {format_duration(audio_duration)}\\\\n\"\n",
    "            f\"Will split into {int(audio_duration / chunk_duration) + 1} chunks of {chunk_duration/60:.0f} minutes each\\\\n\\\\n\"\n",
    "            \"[cyan]Benefits:[/cyan]\\\\n\"\n",
    "            \"â€¢ Prevents memory issues\\\\n\"\n",
    "            \"â€¢ Allows better progress tracking\\\\n\"\n",
    "            \"â€¢ Enables partial recovery if interrupted\",\n",
    "            title=\"[bold yellow]Chunking Large File[/bold yellow]\",\n",
    "            border_style=\"yellow\"\n",
    "        ))\n",
    "        return transcribe_chunked_file(\n",
    "            audio_file, model, output_dir, language, output_format, \n",
    "            multilingual, keepalive, progress, task_id, eta_column, \n",
    "            checkpoint, chunk_duration\n",
    "        )\n",
    "    \n",
    "    # Regular transcription for smaller files\n",
    "    # Prepare output file\n",
    "    output_file = output_dir / f\"{audio_file.stem}.{output_format}\"\n",
    "    \n",
    "    # Create writer\n",
    "    writer = StreamingTranscriptionWriter(output_file, output_format, multilingual)\n",
    "    \n",
    "    # Start transcription\n",
    "    console.print(f\"[cyan]Processing:[/cyan] {audio_file.name} ({format_duration(audio_duration)})\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Update keepalive status\n",
    "    if keepalive:\n",
    "        keepalive.update_status(f\"Transcribing {audio_file.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Transcribe\n",
    "        segments_iterator, info = model.transcribe(\n",
    "            str(audio_file),\n",
    "            language=LANGUAGE_MAP.get(language),\n",
    "            beam_size=5,\n",
    "            vad_filter=True,\n",
    "            vad_parameters=dict(min_silence_duration_ms=500),\n",
    "            multilingual=multilingual\n",
    "        )\n",
    "        \n",
    "        # Process segments with progress tracking\n",
    "        segment_count = 0\n",
    "        audio_position = 0\n",
    "        session_start_time = time.time()\n",
    "        \n",
    "        # Update progress bar total if available\n",
    "        if progress and task_id is not None:\n",
    "            progress.update(task_id, total=info.duration)\n",
    "        \n",
    "        for segment in segments_iterator:\n",
    "            # Skip if resuming and segment is before resume position\n",
    "            if resume_position > 0 and segment.end <= resume_position:\n",
    "                continue\n",
    "                \n",
    "            # Write segment\n",
    "            writer.write_segment(segment)\n",
    "            segment_count += 1\n",
    "            audio_position = segment.end\n",
    "            \n",
    "            # Update checkpoint\n",
    "            if checkpoint:\n",
    "                segment_data = {\n",
    "                    \"text\": segment.text,\n",
    "                    \"start\": segment.start,\n",
    "                    \"end\": segment.end,\n",
    "                    \"language\": getattr(segment, \"language\", None)\n",
    "                }\n",
    "                checkpoint.update_progress(segment_data, audio_position)\n",
    "            \n",
    "            # Update progress\n",
    "            if progress and task_id is not None:\n",
    "                progress.update(task_id, completed=audio_position)\n",
    "                \n",
    "                # Calculate and update ETA\n",
    "                if eta_column and audio_position > 5:  # Wait for 5 seconds before calculating ETA\n",
    "                    elapsed_time = time.time() - session_start_time\n",
    "                    rate = audio_position / elapsed_time\n",
    "                    if rate > 0:\n",
    "                        remaining_audio = info.duration - audio_position\n",
    "                        eta = remaining_audio / rate\n",
    "                        eta_column.set_eta(task_id, eta)\n",
    "            \n",
    "            # Update keepalive with segment info\n",
    "            if keepalive and segment_count % 5 == 0:  # Update every 5 segments\n",
    "                keepalive.update_status(\n",
    "                    f\"Transcribing {audio_file.name} - {segment_count} segments, \"\n",
    "                    f\"{audio_position:.1f}s/{info.duration:.1f}s ({audio_position/info.duration*100:.1f}%)\"\n",
    "                )\n",
    "                \n",
    "            # Periodic memory cleanup to prevent kernel crashes\n",
    "            if segment_count % 100 == 0:\n",
    "                gc.collect()\n",
    "                try:\n",
    "                    import torch\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Close writer\n",
    "        writer.close()\n",
    "        \n",
    "        # Calculate stats\n",
    "        process_time = time.time() - start_time\n",
    "        speed = info.duration / process_time if process_time > 0 else 0\n",
    "        \n",
    "        # Final progress update\n",
    "        if progress and task_id is not None:\n",
    "            progress.update(task_id, completed=info.duration)\n",
    "        \n",
    "        console.print(\n",
    "            f\"[green]âœ“[/green] {audio_file.name} \"\n",
    "            f\"[dim]({info.duration:.1f}s @ {speed:.1f}x speed, {segment_count} segments)[/dim]\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"file\": audio_file.name,\n",
    "            \"duration\": info.duration,\n",
    "            \"segments\": segment_count,\n",
    "            \"process_time\": process_time,\n",
    "            \"speed\": speed,\n",
    "            \"output_file\": str(output_file),\n",
    "            \"detected_language\": info.language if language == \"auto\" else language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        writer.close()\n",
    "        console.print(f\"[red]âœ—[/red] Error processing {audio_file.name}: {e}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"file\": audio_file.name,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def split_large_audio_file(audio_file: Path, chunk_duration: int = 600, temp_dir: Optional[Path] = None, show_progress: bool = True) -> List[Path]:\n",
    "    \"\"\"Split large audio file into chunks using ffmpeg.\n",
    "    \n",
    "    Args:\n",
    "        audio_file: Path to the audio file\n",
    "        chunk_duration: Duration of each chunk in seconds (default: 600 = 10 minutes)\n",
    "        temp_dir: Directory for temporary chunk files\n",
    "        show_progress: Whether to show progress (set to False when called from within a progress context)\n",
    "        \n",
    "    Returns:\n",
    "        List of paths to chunk files\n",
    "    \"\"\"\n",
    "    if temp_dir is None:\n",
    "        temp_dir = audio_file.parent / f\".chunks_{audio_file.stem}\"\n",
    "    \n",
    "    temp_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get audio duration\n",
    "    duration = get_audio_duration(audio_file)\n",
    "    \n",
    "    if duration <= chunk_duration:\n",
    "        # File is small enough, no need to split\n",
    "        return [audio_file]\n",
    "    \n",
    "    console.print(f\"[yellow]Splitting file into {chunk_duration/60:.0f}-minute chunks...[/yellow]\")\n",
    "    \n",
    "    chunk_files = []\n",
    "    num_chunks = int(duration / chunk_duration) + (1 if duration % chunk_duration > 0 else 0)\n",
    "    \n",
    "    console.print(f\"[cyan]Creating {num_chunks} chunks from {audio_file.name}[/cyan]\")\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start_time = i * chunk_duration\n",
    "        chunk_file = temp_dir / f\"{audio_file.stem}_chunk_{i+1:03d}.wav\"\n",
    "        \n",
    "        # Show progress without using Progress bar\n",
    "        console.print(f\"[dim]Creating chunk {i+1}/{num_chunks}...[/dim]\")\n",
    "        \n",
    "        # Use ffmpeg to extract chunk\n",
    "        cmd = [\n",
    "            \"ffmpeg\", \"-y\",  # Overwrite output files\n",
    "            \"-i\", str(audio_file),  # Input file\n",
    "            \"-ss\", str(start_time),  # Start time\n",
    "            \"-t\", str(chunk_duration),  # Duration\n",
    "            \"-acodec\", \"pcm_s16le\",  # Use WAV codec for compatibility\n",
    "            \"-ar\", \"16000\",  # Resample to 16kHz for faster processing\n",
    "            \"-ac\", \"1\",  # Convert to mono\n",
    "            str(chunk_file)  # Output file\n",
    "        ]\n",
    "        \n",
    "        # Run ffmpeg quietly\n",
    "        import subprocess\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode == 0 and chunk_file.exists():\n",
    "            chunk_files.append(chunk_file)\n",
    "            console.print(f\"[green]âœ“[/green] Chunk {i+1} created\")\n",
    "        else:\n",
    "            console.print(f\"[red]Error creating chunk {i+1}: {result.stderr}[/red]\")\n",
    "    \n",
    "    console.print(f\"[green]âœ“ Split into {len(chunk_files)} chunks[/green]\")\n",
    "    return chunk_files\n",
    "\n",
    "def cleanup_chunk_files(chunk_dir: Path):\n",
    "    \"\"\"Clean up temporary chunk files.\"\"\"\n",
    "    if chunk_dir.exists() and chunk_dir.name.startswith(\".chunks_\"):\n",
    "        try:\n",
    "            import shutil\n",
    "            shutil.rmtree(chunk_dir)\n",
    "            console.print(f\"[green]âœ“ Cleaned up temporary chunk files[/green]\")\n",
    "        except Exception as e:\n",
    "            console.print(f\"[yellow]Warning: Could not clean up chunks: {e}[/yellow]\")\n",
    "\n",
    "def transcribe_chunked_file(\n",
    "    audio_file: Path,\n",
    "    model: WhisperModel,\n",
    "    output_dir: Path,\n",
    "    language: str = \"auto\",\n",
    "    output_format: str = \"txt\",\n",
    "    multilingual: bool = False,\n",
    "    keepalive: Optional[ColabKeepalive] = None,\n",
    "    progress: Optional[Progress] = None,\n",
    "    task_id: Optional[int] = None,\n",
    "    eta_column: Optional[RemainingAudioDurationColumn] = None,\n",
    "    checkpoint: Optional[TranscriptionCheckpoint] = None,\n",
    "    chunk_duration: int = 600\n",
    ") -> Dict:\n",
    "    \"\"\"Transcribe a large file by splitting it into chunks.\"\"\"\n",
    "    \n",
    "    # Get total audio duration first\n",
    "    audio_duration = get_audio_duration(audio_file)\n",
    "    \n",
    "    # Split the file into chunks (without showing progress bar since we're already in a progress context)\n",
    "    chunk_dir = audio_file.parent / f\".chunks_{audio_file.stem}\"\n",
    "    chunk_files = split_large_audio_file(audio_file, chunk_duration, chunk_dir, show_progress=False)\n",
    "    \n",
    "    if len(chunk_files) == 1:\n",
    "        # File didn't need splitting after all\n",
    "        return transcribe_file_with_progress(\n",
    "            audio_file, model, output_dir, language, output_format,\n",
    "            multilingual, keepalive, progress, task_id, eta_column,\n",
    "            checkpoint, 0, False  # Disable chunking to avoid recursion\n",
    "        )\n",
    "    \n",
    "    # Prepare output file\n",
    "    output_file = output_dir / f\"{audio_file.stem}.{output_format}\"\n",
    "    temp_output_dir = output_dir / f\".temp_{audio_file.stem}\"\n",
    "    temp_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    console.print(f\"[cyan]Processing {len(chunk_files)} chunks for {audio_file.name}[/cyan]\")\n",
    "    \n",
    "    # Show chunk summary\n",
    "    console.print(Panel(\n",
    "        f\"File: {audio_file.name}\\\\n\"\n",
    "        f\"Total duration: {format_duration(audio_duration)}\\\\n\"\n",
    "        f\"Chunks: {len(chunk_files)} Ã— {chunk_duration/60:.0f} minutes\\\\n\\\\n\"\n",
    "        \"[dim]Progress will be shown for each chunk...[/dim]\",\n",
    "        title=\"[bold cyan]Chunk Processing[/bold cyan]\",\n",
    "        border_style=\"cyan\"\n",
    "    ))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_segments = 0\n",
    "    chunk_results = []\n",
    "    \n",
    "    # Process chunks without creating a new progress bar\n",
    "    try:\n",
    "        for i, chunk_file in enumerate(chunk_files):\n",
    "            chunk_num = i + 1\n",
    "            console.print(f\"\\\\n[yellow]Processing chunk {chunk_num}/{len(chunk_files)}[/yellow]\")\n",
    "            \n",
    "            # Update keepalive\n",
    "            if keepalive:\n",
    "                keepalive.update_status(\n",
    "                    f\"Transcribing {audio_file.name} - Chunk {chunk_num}/{len(chunk_files)}\"\n",
    "                )\n",
    "            \n",
    "            # Update main progress description if available\n",
    "            if progress and task_id is not None:\n",
    "                try:\n",
    "                    progress.update(\n",
    "                        task_id, \n",
    "                        description=f\"[yellow]{audio_file.name} - Chunk {chunk_num}/{len(chunk_files)}[/yellow]\"\n",
    "                    )\n",
    "                except:\n",
    "                    # Ignore if progress update fails\n",
    "                    pass\n",
    "            \n",
    "            # Transcribe chunk\n",
    "            chunk_output = temp_output_dir / f\"chunk_{chunk_num:03d}.{output_format}\"\n",
    "            writer = StreamingTranscriptionWriter(chunk_output, output_format, multilingual)\n",
    "            \n",
    "            try:\n",
    "                segments_iterator, info = model.transcribe(\n",
    "                    str(chunk_file),\n",
    "                    language=LANGUAGE_MAP.get(language),\n",
    "                    beam_size=5,\n",
    "                    vad_filter=True,\n",
    "                    vad_parameters=dict(min_silence_duration_ms=500),\n",
    "                    multilingual=multilingual\n",
    "                )\n",
    "                \n",
    "                chunk_segments = 0\n",
    "                detected_language = None\n",
    "                \n",
    "                for segment in segments_iterator:\n",
    "                    writer.write_segment(segment)\n",
    "                    chunk_segments += 1\n",
    "                    total_segments += 1\n",
    "                    \n",
    "                    if not detected_language and hasattr(info, 'language'):\n",
    "                        detected_language = info.language\n",
    "                    \n",
    "                    # Update progress for main file\n",
    "                    if progress and task_id is not None and not getattr(progress, '_closed', False):\n",
    "                        # Estimate position based on chunk progress\n",
    "                        chunk_position = (i * chunk_duration) + segment.end\n",
    "                        try:\n",
    "                            progress.update(task_id, completed=min(chunk_position, audio_duration))\n",
    "                        except:\n",
    "                            # Ignore if progress is closed or has issues\n",
    "                            pass\n",
    "                    \n",
    "                    # Memory cleanup every 50 segments\n",
    "                    if chunk_segments % 50 == 0:\n",
    "                        gc.collect()\n",
    "                \n",
    "                writer.close()\n",
    "                chunk_results.append({\n",
    "                    \"chunk\": chunk_num,\n",
    "                    \"segments\": chunk_segments,\n",
    "                    \"duration\": info.duration,\n",
    "                    \"language\": detected_language\n",
    "                })\n",
    "                \n",
    "                console.print(f\"[green]âœ“ Chunk {chunk_num}: {chunk_segments} segments[/green]\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                console.print(f\"[red]Error in chunk {chunk_num}: {e}[/red]\")\n",
    "                writer.close()\n",
    "            \n",
    "            # Show chunk completion with progress\n",
    "            progress_pct = ((i + 1) / len(chunk_files)) * 100\n",
    "            console.print(f\"[bold green]Chunk {chunk_num}/{len(chunk_files)} complete - Overall progress: {progress_pct:.0f}%[/bold green]\\\\n\")\n",
    "            \n",
    "            # Clean up chunk file immediately to save space\n",
    "            try:\n",
    "                chunk_file.unlink()\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Combine all chunk outputs into final file\n",
    "        console.print(f\"\\\\n[cyan]Combining {len(chunk_files)} chunks into final output...[/cyan]\")\n",
    "        combine_chunk_outputs(temp_output_dir, output_file, output_format)\n",
    "        \n",
    "        # Clean up\n",
    "        cleanup_chunk_files(chunk_dir)\n",
    "        import shutil\n",
    "        if temp_output_dir.exists():\n",
    "            shutil.rmtree(temp_output_dir)\n",
    "            \n",
    "        # Restore progress bar description if needed\n",
    "        if progress and task_id is not None:\n",
    "            progress.update(task_id, description=f\"[yellow]{audio_file.name}[/yellow]\")\n",
    "        \n",
    "        # Calculate final stats\n",
    "        process_time = time.time() - start_time\n",
    "        speed = audio_duration / process_time if process_time > 0 else 0\n",
    "        \n",
    "        # Detect primary language from chunks\n",
    "        detected_language = None\n",
    "        if chunk_results and chunk_results[0].get(\"language\"):\n",
    "            detected_language = chunk_results[0][\"language\"]\n",
    "        \n",
    "        console.print(\n",
    "            f\"[green]âœ“[/green] {audio_file.name} \"\n",
    "            f\"[dim]({audio_duration:.1f}s @ {speed:.1f}x speed, {total_segments} segments across {len(chunk_files)} chunks)[/dim]\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"file\": audio_file.name,\n",
    "            \"duration\": audio_duration,\n",
    "            \"segments\": total_segments,\n",
    "            \"process_time\": process_time,\n",
    "            \"speed\": speed,\n",
    "            \"output_file\": str(output_file),\n",
    "            \"detected_language\": detected_language,\n",
    "            \"chunks_processed\": len(chunk_files)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Clean up on error\n",
    "        cleanup_chunk_files(chunk_dir)\n",
    "        import shutil\n",
    "        if temp_output_dir.exists():\n",
    "            shutil.rmtree(temp_output_dir)\n",
    "        \n",
    "        console.print(f\"[red]âœ—[/red] Error processing chunked file {audio_file.name}: {e}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"file\": audio_file.name,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def combine_chunk_outputs(temp_dir: Path, output_file: Path, format_type: str):\n",
    "    \"\"\"Combine multiple chunk output files into a single file.\"\"\"\n",
    "    chunk_files = sorted(temp_dir.glob(f\"chunk_*.{format_type}\"))\n",
    "    \n",
    "    if not chunk_files:\n",
    "        console.print(\"[red]No chunk outputs found to combine![/red]\")\n",
    "        return\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        if format_type == \"vtt\":\n",
    "            outfile.write(\"WEBVTT\\\\n\\\\n\")\n",
    "        \n",
    "        segment_number = 1\n",
    "        \n",
    "        for chunk_file in chunk_files:\n",
    "            with open(chunk_file, 'r', encoding='utf-8') as infile:\n",
    "                content = infile.read()\n",
    "                \n",
    "                if format_type == \"txt\":\n",
    "                    # Simple concatenation for text files\n",
    "                    outfile.write(content)\n",
    "                    if not content.endswith('\\\\n'):\n",
    "                        outfile.write('\\\\n')\n",
    "                \n",
    "                elif format_type == \"srt\":\n",
    "                    # Renumber segments for SRT\n",
    "                    lines = content.strip().split('\\\\n')\n",
    "                    i = 0\n",
    "                    while i < len(lines):\n",
    "                        if lines[i].strip().isdigit():\n",
    "                            outfile.write(f\"{segment_number}\\\\n\")\n",
    "                            segment_number += 1\n",
    "                            i += 1\n",
    "                            # Write timestamp and text lines\n",
    "                            while i < len(lines) and lines[i].strip():\n",
    "                                outfile.write(lines[i] + '\\\\n')\n",
    "                                i += 1\n",
    "                            outfile.write('\\\\n')\n",
    "                        else:\n",
    "                            i += 1\n",
    "                \n",
    "                elif format_type == \"vtt\":\n",
    "                    # Skip WEBVTT header for chunks\n",
    "                    lines = content.strip().split('\\\\n')\n",
    "                    skip_header = True\n",
    "                    for line in lines:\n",
    "                        if skip_header and line.strip() == \"WEBVTT\":\n",
    "                            skip_header = False\n",
    "                            continue\n",
    "                        if skip_header and not line.strip():\n",
    "                            skip_header = False\n",
    "                            continue\n",
    "                        if line.strip():\n",
    "                            outfile.write(line + '\\\\n')\n",
    "                    outfile.write('\\\\n')\n",
    "    \n",
    "    console.print(f\"[green]âœ“ Combined {len(chunk_files)} chunks into {output_file.name}[/green]\")\n",
    "\n",
    "def find_audio_files(input_path: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in the given path.\"\"\"\n",
    "    audio_files = []\n",
    "    \n",
    "    if input_path.is_file():\n",
    "        if input_path.suffix.lower() in AUDIO_EXTENSIONS:\n",
    "            audio_files.append(input_path)\n",
    "    else:\n",
    "        for ext in AUDIO_EXTENSIONS:\n",
    "            audio_files.extend(input_path.glob(f\"*{ext}\"))\n",
    "            audio_files.extend(input_path.glob(f\"*{ext.upper()}\"))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def transcribe_folder(\n",
    "    input_path: Path,\n",
    "    output_path: Path,\n",
    "    model_size: str = \"base\",\n",
    "    language: str = \"auto\",\n",
    "    output_format: str = \"txt\",\n",
    "    multilingual: bool = False,\n",
    "    checkpoint_dir: Optional[Path] = None,\n",
    "    chunk_duration: int = 600,\n",
    "    chunk_threshold: int = 900\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Transcribe all audio files in a folder with checkpoint support.\"\"\"\n",
    "    \n",
    "    # Set checkpoint directory\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = output_path / \".checkpoints\"\n",
    "    \n",
    "    # Initialize checkpoint\n",
    "    checkpoint = TranscriptionCheckpoint(checkpoint_dir)\n",
    "    \n",
    "    # Check for existing checkpoint\n",
    "    resume_info = None\n",
    "    if checkpoint.load():\n",
    "        console.print(Panel(\n",
    "            f\"[yellow]Found previous transcription checkpoint[/yellow]\\\\n\"\n",
    "            f\"Completed files: {len(checkpoint.state['files_completed'])}\\\\n\"\n",
    "            f\"Timestamp: {checkpoint.state['timestamp']}\",\n",
    "            title=\"[bold cyan]Resume Transcription?[/bold cyan]\",\n",
    "            border_style=\"cyan\"\n",
    "        ))\n",
    "        \n",
    "        try:\n",
    "            # In Colab, default to resume to avoid losing progress\n",
    "            resume = True\n",
    "            console.print(\"[green]Resuming from checkpoint...[/green]\")\n",
    "        except:\n",
    "            resume = True\n",
    "            \n",
    "        if resume:\n",
    "            resume_info = checkpoint.get_resume_info()\n",
    "        else:\n",
    "            checkpoint.clear()\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_files = find_audio_files(input_path)\n",
    "    \n",
    "    if not audio_files:\n",
    "        console.print(\"[red]No audio files found![/red]\")\n",
    "        return []\n",
    "    \n",
    "    # Filter out completed files if resuming\n",
    "    if resume_info and resume_info[\"completed_files\"]:\n",
    "        original_count = len(audio_files)\n",
    "        audio_files = [f for f in audio_files if f.name not in resume_info[\"completed_files\"]]\n",
    "        console.print(f\"[green]Skipping {original_count - len(audio_files)} already completed files[/green]\")\n",
    "    \n",
    "    console.print(f\"[green]Found {len(audio_files)} audio files to process[/green]\")\n",
    "    \n",
    "    # Analyze total audio duration\n",
    "    total_duration = 0\n",
    "    console.print(\"[cyan]Analyzing audio files...[/cyan]\")\n",
    "    for audio_file in audio_files:\n",
    "        duration = get_audio_duration(audio_file)\n",
    "        total_duration += duration\n",
    "        console.print(f\"  â€¢ {audio_file.name}: {format_duration(duration)}\")\n",
    "    \n",
    "    console.print(f\"[green]Total audio duration: {format_duration(total_duration)}[/green]\\\\n\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load model with retry logic\n",
    "    device, compute_type = detect_device_and_compute_type()\n",
    "    console.print(f\"[cyan]Loading Whisper {model_size} model...[/cyan]\")\n",
    "    \n",
    "    try:\n",
    "        # Don't use console.status if we're already in a progress context\n",
    "        console.print(\"[cyan]Loading model, please wait...[/cyan]\")\n",
    "        model = load_whisper_model_with_retry(model_size, device=device, compute_type=compute_type)\n",
    "        console.print(f\"[green]âœ“[/green] Model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error loading model: {e}[/red]\")\n",
    "        console.print(\"\\\\n[yellow]Alternative solution:[/yellow]\")\n",
    "        console.print(\"Try running this command first to clear cache:\")\n",
    "        console.print(\"[cyan]!rm -rf /root/.cache/huggingface[/cyan]\")\n",
    "        console.print(\"Then restart the runtime and try again.\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize keepalive\n",
    "    keepalive = ColabKeepalive()\n",
    "    keepalive.start()\n",
    "    \n",
    "    # Process files with enhanced progress\n",
    "    results = []\n",
    "    eta_column = RemainingAudioDurationColumn()\n",
    "    \n",
    "    try:\n",
    "        with Progress(\n",
    "            SpinnerColumn(spinner_name=\"dots12\", style=\"cyan\"),\n",
    "            TextColumn(\"[bold blue]{task.description}\"),\n",
    "            BarColumn(bar_width=40, style=\"cyan\", complete_style=\"green\"),\n",
    "            TaskProgressColumn(),\n",
    "            \"â€¢\",\n",
    "            TimeElapsedColumn(),\n",
    "            \"â€¢\",\n",
    "            eta_column,\n",
    "            console=console,\n",
    "            refresh_per_second=1\n",
    "        ) as progress:\n",
    "            # Main task for overall progress\n",
    "            main_task = progress.add_task(\n",
    "                f\"[cyan]Overall Progress ({len(audio_files)} files)\", \n",
    "                total=total_duration\n",
    "            )\n",
    "            \n",
    "            # Individual file task\n",
    "            file_task = progress.add_task(\"[yellow]Current file\", visible=False)\n",
    "            \n",
    "            total_processed = 0\n",
    "            \n",
    "            for idx, audio_file in enumerate(audio_files, 1):\n",
    "                # Check if this is the file we need to resume\n",
    "                resume_position = 0\n",
    "                if resume_info and resume_info[\"current_file\"] == audio_file.name:\n",
    "                    resume_position = resume_info[\"current_position\"]\n",
    "                    console.print(f\"[yellow]Resuming {audio_file.name} from position {resume_position:.1f}s[/yellow]\")\n",
    "                \n",
    "                # Set current file in checkpoint\n",
    "                checkpoint.set_current_file(audio_file.name)\n",
    "                \n",
    "                # Update file task\n",
    "                progress.update(\n",
    "                    file_task, \n",
    "                    description=f\"[yellow]File {idx}/{len(audio_files)}: {audio_file.name}\",\n",
    "                    visible=True,\n",
    "                    completed=resume_position\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    # Transcribe with progress\n",
    "                    result = transcribe_file_with_progress(\n",
    "                        audio_file, model, output_path, \n",
    "                        language, output_format, multilingual,\n",
    "                        keepalive, progress, file_task, eta_column,\n",
    "                        checkpoint, resume_position,\n",
    "                        chunk_large_files=True,\n",
    "                        chunk_duration=chunk_duration,\n",
    "                        chunk_threshold=chunk_threshold\n",
    "                    )\n",
    "                    \n",
    "                    results.append(result)\n",
    "                    \n",
    "                    # Update overall progress\n",
    "                    if result[\"success\"]:\n",
    "                        total_processed += result[\"duration\"]\n",
    "                        progress.update(main_task, completed=total_processed)\n",
    "                        # Mark file as complete in checkpoint\n",
    "                        checkpoint.mark_file_complete(audio_file.name)\n",
    "                    \n",
    "                    # Hide file task between files\n",
    "                    progress.update(file_task, visible=False)\n",
    "                    \n",
    "                    # Force save checkpoint after each file\n",
    "                    checkpoint.save()\n",
    "                    \n",
    "                    # Memory cleanup between files\n",
    "                    gc.collect()\n",
    "                    try:\n",
    "                        import torch\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    console.print(f\"[red]Error processing {audio_file.name}: {e}[/red]\")\n",
    "                    results.append({\n",
    "                        \"success\": False,\n",
    "                        \"file\": audio_file.name,\n",
    "                        \"error\": str(e)\n",
    "                    })\n",
    "                    # Continue with next file even if one fails\n",
    "                    continue\n",
    "            \n",
    "            # Ensure main task shows completion\n",
    "            progress.update(main_task, completed=total_duration)\n",
    "    \n",
    "    finally:\n",
    "        # Stop keepalive\n",
    "        keepalive.stop()\n",
    "        print()  # Clear the keepalive line\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_results_summary(results: List[Dict]):\n",
    "    \"\"\"Display a summary of transcription results.\"\"\"\n",
    "    if not results:\n",
    "        return\n",
    "    \n",
    "    # Create summary table\n",
    "    table = Table(title=\"ðŸ“Š Transcription Results\", show_header=True, header_style=\"bold cyan\")\n",
    "    table.add_column(\"File\", style=\"cyan\", width=30)\n",
    "    table.add_column(\"Status\", style=\"green\")\n",
    "    table.add_column(\"Duration\", justify=\"right\")\n",
    "    table.add_column(\"Segments\", justify=\"right\")\n",
    "    table.add_column(\"Speed\", justify=\"right\")\n",
    "    table.add_column(\"Chunks\", justify=\"right\")\n",
    "    \n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    total_duration = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for result in results:\n",
    "        if result[\"success\"]:\n",
    "            successful += 1\n",
    "            total_duration += result[\"duration\"]\n",
    "            total_time += result[\"process_time\"]\n",
    "            \n",
    "            chunks_info = str(result.get(\"chunks_processed\", 1))\n",
    "            if result.get(\"chunks_processed\", 1) > 1:\n",
    "                chunks_info = f\"[yellow]{chunks_info}[/yellow]\"\n",
    "            \n",
    "            table.add_row(\n",
    "                result[\"file\"][:30] + \"...\" if len(result[\"file\"]) > 30 else result[\"file\"],\n",
    "                \"âœ… Success\",\n",
    "                format_duration(result[\"duration\"]),\n",
    "                str(result[\"segments\"]),\n",
    "                f\"{result['speed']:.1f}x\",\n",
    "                chunks_info\n",
    "            )\n",
    "        else:\n",
    "            failed += 1\n",
    "            error_msg = str(result[\"error\"])[:20] + \"...\" if len(str(result[\"error\"])) > 20 else str(result[\"error\"])\n",
    "            table.add_row(\n",
    "                result[\"file\"][:30] + \"...\" if len(result[\"file\"]) > 30 else result[\"file\"],\n",
    "                f\"âŒ {error_msg}\",\n",
    "                \"-\",\n",
    "                \"-\",\n",
    "                \"-\",\n",
    "                \"-\"\n",
    "            )\n",
    "    \n",
    "    console.print(\"\\\\n\")\n",
    "    console.print(table)\n",
    "    \n",
    "    # Summary statistics\n",
    "    if successful > 0:\n",
    "        avg_speed = total_duration / total_time if total_time > 0 else 0\n",
    "        console.print(\"\\\\n\")\n",
    "        console.print(Panel(\n",
    "            f\"[bold]Summary:[/bold]\\\\n\\\\n\"\n",
    "            f\"âœ… Successful: {successful} files\\\\n\"\n",
    "            f\"âŒ Failed: {failed} files\\\\n\"\n",
    "            f\"â±ï¸  Total audio: {format_duration(total_duration)}\\\\n\"\n",
    "            f\"âš¡ Processing time: {format_duration(total_time)}\\\\n\"\n",
    "            f\"ðŸš€ Average speed: {avg_speed:.1f}x realtime\",\n",
    "            title=\"[bold green]Transcription Complete![/bold green]\",\n",
    "            border_style=\"green\"\n",
    "        ))\n",
    "'''\n",
    "\n",
    "with open('/content/transcript_pkg/file_transcribe.py', 'w') as f:\n",
    "    f.write(file_transcribe_code)\n",
    "\n",
    "print(\"âœ… Enhanced file_transcribe.py created with segment progress tracking and keepalive!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### âš ï¸ Troubleshooting: Model Loading Issues\n",
    "\n",
    "If you encounter a **\"502 Bad Gateway\"** or similar error when loading the model, this is usually due to Hugging Face connectivity issues. The notebook now includes retry logic to handle this automatically. However, if the issue persists:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear Hugging Face cache if you encounter model loading errors\n",
    "# Uncomment and run if needed:\n",
    "# !rm -rf /root/.cache/huggingface\n",
    "# !rm -rf /content/whisper_models\n",
    "\n",
    "# After running this, restart the runtime: Runtime â†’ Restart runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Configure Transcription Settings\n",
    "\n",
    "Modify the parameters below according to your needs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters - MODIFY THESE AS NEEDED\n",
    "\n",
    "# Input path in Google Drive (can be a file or folder)\n",
    "INPUT_PATH = \"/content/drive/MyDrive/AudioFiles\"  # @param {type:\"string\"}\n",
    "\n",
    "# Output path in Google Drive  \n",
    "OUTPUT_PATH = \"/content/drive/MyDrive/Transcriptions\"  # @param {type:\"string\"}\n",
    "\n",
    "# Model size: tiny, base, small, medium, large\n",
    "MODEL_SIZE = \"base\"  # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "\n",
    "# Language: en (English), pt (Portuguese), auto (auto-detect)\n",
    "LANGUAGE = \"auto\"  # @param [\"auto\", \"en\", \"pt\"]\n",
    "\n",
    "# Output format: txt, srt, vtt\n",
    "OUTPUT_FORMAT = \"txt\"  # @param [\"txt\", \"srt\", \"vtt\"]\n",
    "\n",
    "# Enable multilingual mode (shows language for each segment)\n",
    "MULTILINGUAL = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# Chunk duration in minutes for large files (0 to disable chunking)\n",
    "CHUNK_DURATION_MINUTES = 10  # @param {type:\"slider\", min:0, max:30, step:5}\n",
    "\n",
    "# File size threshold for chunking (in minutes)\n",
    "CHUNK_THRESHOLD_MINUTES = 15  # @param {type:\"slider\", min:10, max:60, step:5}\n",
    "\n",
    "print(\"ðŸ“‹ Configuration:\")\n",
    "print(f\"  Input: {INPUT_PATH}\")\n",
    "print(f\"  Output: {OUTPUT_PATH}\")\n",
    "print(f\"  Model: {MODEL_SIZE}\")\n",
    "print(f\"  Language: {LANGUAGE}\")\n",
    "print(f\"  Format: {OUTPUT_FORMAT}\")\n",
    "print(f\"  Multilingual: {MULTILINGUAL}\")\n",
    "if CHUNK_DURATION_MINUTES > 0:\n",
    "    print(f\"  Chunking: Files > {CHUNK_THRESHOLD_MINUTES}min split into {CHUNK_DURATION_MINUTES}min chunks\")\n",
    "else:\n",
    "    print(f\"  Chunking: Disabled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Optional: Clear Previous Checkpoints\n",
    "\n",
    "If you want to start fresh and clear any previous checkpoints, run this cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clear checkpoints to start fresh\n",
    "# Uncomment the lines below if you want to remove previous checkpoint data\n",
    "\n",
    "# import shutil\n",
    "# checkpoint_path = Path(OUTPUT_PATH) / \".checkpoints\"\n",
    "# if checkpoint_path.exists():\n",
    "#     shutil.rmtree(checkpoint_path)\n",
    "#     print(\"âœ… Checkpoints cleared!\")\n",
    "# else:\n",
    "#     print(\"â„¹ï¸ No checkpoints found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Run Transcription\n",
    "\n",
    "Execute the cell below to start the transcription process. The notebook will:\n",
    "- Keep your Colab connection alive during long transcriptions\n",
    "- Show segment-by-segment progress with ETA\n",
    "- Automatically handle connection issues\n",
    "- Save checkpoints for resume capability\n",
    "- Split large files into chunks automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('/content')\n",
    "\n",
    "from transcript_pkg.file_transcribe import transcribe_folder, display_results_summary\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Convert paths\n",
    "input_path = Path(INPUT_PATH)\n",
    "output_path = Path(OUTPUT_PATH)\n",
    "\n",
    "# Check if input exists\n",
    "if not input_path.exists():\n",
    "    console.print(f\"[red]Error: Input path does not exist: {INPUT_PATH}[/red]\")\n",
    "    console.print(\"[yellow]Please check your INPUT_PATH and ensure the folder/file exists in your Google Drive.[/yellow]\")\n",
    "else:\n",
    "    # Run transcription\n",
    "    console.print(Panel(\n",
    "        \"[bold green]Starting Transcription Process[/bold green]\\n\\n\"\n",
    "        \"This may take a while depending on the size and number of files.\\n\"\n",
    "        \"The process will use GPU acceleration if available.\\n\\n\"\n",
    "        \"[cyan]Features:[/cyan]\\n\"\n",
    "        \"â€¢ Segment-by-segment progress tracking\\n\"\n",
    "        \"â€¢ Real-time ETA calculations\\n\"\n",
    "        \"â€¢ Automatic checkpoint saving\\n\"\n",
    "        \"â€¢ Connection keepalive for long runs\\n\"\n",
    "        \"â€¢ Automatic chunking for large files\",\n",
    "        title=\"[bold cyan]Audio Transcription[/bold cyan]\",\n",
    "        border_style=\"cyan\"\n",
    "    ))\n",
    "    \n",
    "    # Convert chunk parameters from minutes to seconds\n",
    "    chunk_duration = CHUNK_DURATION_MINUTES * 60 if CHUNK_DURATION_MINUTES > 0 else 0\n",
    "    chunk_threshold = CHUNK_THRESHOLD_MINUTES * 60\n",
    "    \n",
    "    # Run transcription with all parameters\n",
    "    results = transcribe_folder(\n",
    "        input_path=input_path,\n",
    "        output_path=output_path,\n",
    "        model_size=MODEL_SIZE,\n",
    "        language=LANGUAGE,\n",
    "        output_format=OUTPUT_FORMAT,\n",
    "        multilingual=MULTILINGUAL,\n",
    "        chunk_duration=chunk_duration,\n",
    "        chunk_threshold=chunk_threshold\n",
    "    )\n",
    "    \n",
    "    # Display results summary\n",
    "    display_results_summary(results)\n",
    "    \n",
    "    console.print(f\"\\n[green]âœ… All transcriptions saved to:[/green] {OUTPUT_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
