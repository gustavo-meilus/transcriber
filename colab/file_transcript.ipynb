{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 🎙️ Audio Transcription with Google Drive Integration\n",
    "\n",
    "This notebook allows you to transcribe audio files stored in your Google Drive using the `transcript_pkg`.\n",
    "\n",
    "## Features:\n",
    "- 📁 Transcribe single files or entire folders\n",
    "- 🌐 Support for multiple languages (English, Portuguese, Auto-detect)\n",
    "- 📝 Multiple output formats (TXT, SRT, VTT)\n",
    "- 🚀 GPU acceleration support\n",
    "- 💾 Save results directly to Google Drive\n",
    "- 📊 Segment-based progress tracking with ETA\n",
    "- 🔄 Connection keepalive for long transcriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Tips and Best Practices\n",
    "\n",
    "### Model Selection Guide:\n",
    "- **tiny**: Fastest (39M parameters) - Good for quick drafts\n",
    "- **base**: Balanced (74M parameters) - Recommended for most use cases\n",
    "- **small**: Better accuracy (244M parameters) - Good for important content\n",
    "- **medium**: High accuracy (769M parameters) - For professional use\n",
    "- **large**: Best accuracy (1550M parameters) - When quality is critical\n",
    "\n",
    "### Performance Tips:\n",
    "1. **GPU Acceleration**: Google Colab provides free GPU access. Always check GPU is enabled: Runtime → Change runtime type → GPU\n",
    "2. **Batch Processing**: Process multiple files at once for efficiency\n",
    "3. **File Size**: For very long audio files (>1 hour), the notebook now includes:\n",
    "   - Connection keepalive to prevent timeouts\n",
    "   - Automatic checkpointing to Google Drive\n",
    "   - Resume capability if kernel restarts\n",
    "   - Memory management to prevent crashes\n",
    "\n",
    "### Language Settings:\n",
    "- Use `auto` for mixed-language content or when unsure\n",
    "- Use specific language codes (`en`, `pt`) for better accuracy when language is known\n",
    "- Enable `multilingual` mode for content with multiple languages\n",
    "\n",
    "### Output Formats:\n",
    "- **txt**: Plain text, best for reading and searching\n",
    "- **srt**: Subtitle format with timestamps, compatible with most video players\n",
    "- **vtt**: WebVTT format, ideal for web-based video players\n",
    "\n",
    "### Troubleshooting:\n",
    "- If transcription fails, check file format is supported\n",
    "- Ensure sufficient Google Drive storage space\n",
    "- For large batches, monitor Colab runtime limits\n",
    "- Clear Colab disk space if needed: `!rm -rf /content/*`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Mount Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print(\"✅ Google Drive mounted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q faster-whisper rich tinytag scipy sounddevice numpy\n",
    "\n",
    "# Install ffmpeg for audio processing\n",
    "!apt-get -qq install -y ffmpeg\n",
    "\n",
    "print(\"✅ All dependencies installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Setup transcript_pkg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup transcript_pkg by copying the actual files\n",
    "# You can either clone your repository or upload the transcript_pkg folder to Colab\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Option 1: If you have the transcript_pkg in your repository\n",
    "# !git clone https://github.com/yourusername/transcriber.git /content/transcriber\n",
    "\n",
    "# Option 2: Create a minimal version for Colab\n",
    "os.makedirs('/content/transcript_pkg', exist_ok=True)\n",
    "\n",
    "# Create __init__.py\n",
    "with open('/content/transcript_pkg/__init__.py', 'w') as f:\n",
    "    f.write('\"\"\"Audio transcription tools for live and file-based transcription.\"\"\"\\n\\n__version__ = \"0.1.0\"\\n')\n",
    "\n",
    "print(\"✅ transcript_pkg directory created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enhanced file_transcribe module for Google Colab with checkpointing and segment progress\n",
    "file_transcribe_code = '''\"\"\"Enhanced file transcription module for Google Colab with checkpointing, connection keepalive and segment-based progress tracking.\"\"\"\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "import threading\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "import signal\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "from rich.console import Console\n",
    "from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn, TimeElapsedColumn, ProgressColumn, Task\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "from rich.text import Text\n",
    "from rich.live import Live\n",
    "from rich.prompt import Confirm\n",
    "from tinytag import TinyTag\n",
    "\n",
    "console = Console()\n",
    "\n",
    "AUDIO_EXTENSIONS = {\n",
    "    \".mp3\", \".wav\", \".flac\", \".ogg\", \".m4a\", \".mp4\", \n",
    "    \".aac\", \".wma\", \".opus\", \".webm\", \".mkv\", \".avi\", \".mov\", \".m4v\"\n",
    "}\n",
    "\n",
    "LANGUAGE_MAP = {\n",
    "    \"en\": \"en\",\n",
    "    \"pt\": \"pt\", \n",
    "    \"auto\": None\n",
    "}\n",
    "\n",
    "# Colab keepalive settings\n",
    "COLAB_KEEPALIVE_INTERVAL = 20  # seconds (reduced for better keepalive)\n",
    "CHECKPOINT_SAVE_INTERVAL = 30  # Save checkpoint every 30 segments\n",
    "\n",
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to timestamp format.\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = seconds % 60\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:06.3f}\"\n",
    "\n",
    "def format_duration(seconds: float) -> str:\n",
    "    \"\"\"Format duration in human-readable format.\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}s\"\n",
    "    elif seconds < 3600:\n",
    "        return f\"{seconds/60:.1f}m\"\n",
    "    else:\n",
    "        return f\"{seconds/3600:.1f}h\"\n",
    "\n",
    "def format_duration_hhmmss(seconds: float) -> str:\n",
    "    \"\"\"Format duration in seconds as HH:MM:SS.\"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
    "\n",
    "def get_audio_duration(file_path: Path) -> float:\n",
    "    \"\"\"Get actual audio duration using TinyTag.\"\"\"\n",
    "    try:\n",
    "        tag = TinyTag.get(file_path)\n",
    "        return tag.duration or 0.0\n",
    "    except Exception:\n",
    "        return 0.0  # Return 0 if duration can't be read\n",
    "\n",
    "class TranscriptionCheckpoint:\n",
    "    \"\"\"Manage transcription progress checkpoints for Google Drive.\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir: Path):\n",
    "        \"\"\"Initialize checkpoint manager.\"\"\"\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.state_file = self.checkpoint_dir / \"transcription_state.json\"\n",
    "        self.state = {\n",
    "            \"files_completed\": [],\n",
    "            \"current_file\": None,\n",
    "            \"current_file_segments\": [],\n",
    "            \"current_file_position\": 0,\n",
    "            \"total_files\": 0,\n",
    "            \"model_size\": None,\n",
    "            \"language\": None,\n",
    "            \"output_format\": None,\n",
    "            \"multilingual\": False,\n",
    "            \"timestamp\": None\n",
    "        }\n",
    "        \n",
    "    def load(self) -> bool:\n",
    "        \"\"\"Load checkpoint state from Google Drive.\"\"\"\n",
    "        if self.state_file.exists():\n",
    "            try:\n",
    "                with open(self.state_file, 'r') as f:\n",
    "                    self.state = json.load(f)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                console.print(f\"[yellow]Warning: Could not load checkpoint: {e}[/yellow]\")\n",
    "                return False\n",
    "        return False\n",
    "        \n",
    "    def save(self):\n",
    "        \"\"\"Save checkpoint state to Google Drive.\"\"\"\n",
    "        self.state[\"timestamp\"] = datetime.now().isoformat()\n",
    "        try:\n",
    "            with open(self.state_file, 'w') as f:\n",
    "                json.dump(self.state, f, indent=2)\n",
    "            # Force sync to Google Drive\n",
    "            os.sync()\n",
    "        except Exception as e:\n",
    "            console.print(f\"[yellow]Warning: Could not save checkpoint: {e}[/yellow]\")\n",
    "            \n",
    "    def mark_file_complete(self, file_name: str):\n",
    "        \"\"\"Mark a file as completed.\"\"\"\n",
    "        if file_name not in self.state[\"files_completed\"]:\n",
    "            self.state[\"files_completed\"].append(file_name)\n",
    "        self.state[\"current_file\"] = None\n",
    "        self.state[\"current_file_segments\"] = []\n",
    "        self.state[\"current_file_position\"] = 0\n",
    "        self.save()\n",
    "        \n",
    "    def set_current_file(self, file_name: str):\n",
    "        \"\"\"Set the current file being processed.\"\"\"\n",
    "        self.state[\"current_file\"] = file_name\n",
    "        self.save()\n",
    "        \n",
    "    def update_progress(self, segment_data: dict, position: float):\n",
    "        \"\"\"Update progress for current file.\"\"\"\n",
    "        self.state[\"current_file_segments\"].append(segment_data)\n",
    "        self.state[\"current_file_position\"] = position\n",
    "        # Save every 10 segments\n",
    "        if len(self.state[\"current_file_segments\"]) % 10 == 0:\n",
    "            self.save()\n",
    "            \n",
    "    def get_resume_info(self) -> dict:\n",
    "        \"\"\"Get information for resuming transcription.\"\"\"\n",
    "        return {\n",
    "            \"completed_files\": self.state[\"files_completed\"],\n",
    "            \"current_file\": self.state[\"current_file\"],\n",
    "            \"current_position\": self.state[\"current_file_position\"],\n",
    "            \"segments\": self.state[\"current_file_segments\"]\n",
    "        }\n",
    "        \n",
    "    def clear(self):\n",
    "        \"\"\"Clear all checkpoint data.\"\"\"\n",
    "        try:\n",
    "            if self.state_file.exists():\n",
    "                self.state_file.unlink()\n",
    "            # Clear state\n",
    "            self.state = {\n",
    "                \"files_completed\": [],\n",
    "                \"current_file\": None,\n",
    "                \"current_file_segments\": [],\n",
    "                \"current_file_position\": 0,\n",
    "                \"total_files\": 0,\n",
    "                \"model_size\": None,\n",
    "                \"language\": None,\n",
    "                \"output_format\": None,\n",
    "                \"multilingual\": False,\n",
    "                \"timestamp\": None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            console.print(f\"[yellow]Warning: Could not clear checkpoint: {e}[/yellow]\")\n",
    "\n",
    "class ColabKeepalive:\n",
    "    \"\"\"Keep Colab connection alive by periodically outputting status.\"\"\"\n",
    "    \n",
    "    def __init__(self, interval: int = COLAB_KEEPALIVE_INTERVAL):\n",
    "        self.interval = interval\n",
    "        self.running = False\n",
    "        self.thread = None\n",
    "        self.last_status = \"\"\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"Start the keepalive thread.\"\"\"\n",
    "        self.running = True\n",
    "        self.thread = threading.Thread(target=self._keepalive_loop, daemon=True)\n",
    "        self.thread.start()\n",
    "        \n",
    "    def stop(self):\n",
    "        \"\"\"Stop the keepalive thread.\"\"\"\n",
    "        self.running = False\n",
    "        if self.thread:\n",
    "            self.thread.join(timeout=2)\n",
    "            \n",
    "    def update_status(self, status: str):\n",
    "        \"\"\"Update the status message.\"\"\"\n",
    "        self.last_status = status\n",
    "        \n",
    "    def _keepalive_loop(self):\n",
    "        \"\"\"Main keepalive loop.\"\"\"\n",
    "        from IPython.display import clear_output\n",
    "        while self.running:\n",
    "            # Output a minimal update to keep connection alive\n",
    "            timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "            # Use IPython display for better Colab compatibility\n",
    "            clear_output(wait=True)\n",
    "            print(f\"⏳ {timestamp} - {self.last_status}\")\n",
    "            time.sleep(self.interval)\n",
    "\n",
    "class RemainingAudioDurationColumn(ProgressColumn):\n",
    "    \"\"\"Custom column showing the calculated ETA with a live countdown.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.task_etas = {}  # task_id -> (eta_in_seconds, last_update_time)\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def set_eta(self, task_id: int, eta: float):\n",
    "        \"\"\"Set the ETA for a specific task.\"\"\"\n",
    "        with self.lock:\n",
    "            self.task_etas[task_id] = (eta, time.time())\n",
    "\n",
    "    def render(self, task: Task) -> Text:\n",
    "        \"\"\"Render the ETA by calculating the remaining time since the last update.\"\"\"\n",
    "        with self.lock:\n",
    "            eta_info = self.task_etas.get(task.id)\n",
    "            if eta_info:\n",
    "                eta, last_update_time = eta_info\n",
    "                time_elapsed = time.time() - last_update_time\n",
    "                current_eta = eta - time_elapsed\n",
    "\n",
    "                if current_eta > 0:\n",
    "                    return Text(format_duration_hhmmss(current_eta), style=\"bold\")\n",
    "\n",
    "        return Text(\"--:--:--\", style=\"bold\")\n",
    "\n",
    "class StreamingTranscriptionWriter:\n",
    "    \"\"\"Handles streaming output of transcription data.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_file: Path, format_type: str, multilingual: bool = False):\n",
    "        self.output_file = output_file\n",
    "        self.format_type = format_type\n",
    "        self.multilingual = multilingual\n",
    "        self.segment_count = 0\n",
    "        self.file_handle = None\n",
    "        self._initialize_file()\n",
    "    \n",
    "    def _initialize_file(self):\n",
    "        \"\"\"Initialize the output file with headers if needed.\"\"\"\n",
    "        self.output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if self.format_type == \"txt\":\n",
    "            self.file_handle = open(self.output_file, \"w\", encoding=\"utf-8\")\n",
    "            if self.multilingual:\n",
    "                self.file_handle.write(\"[Multilingual transcription - language shown in brackets]\\\\\\\\n\\\\\\\\n\")\n",
    "        elif self.format_type == \"vtt\":\n",
    "            self.file_handle = open(self.output_file, \"w\", encoding=\"utf-8\")\n",
    "            self.file_handle.write(\"WEBVTT\\\\\\\\n\\\\\\\\n\")\n",
    "        elif self.format_type == \"srt\":\n",
    "            self.file_handle = open(self.output_file, \"w\", encoding=\"utf-8\")\n",
    "    \n",
    "    def write_segment(self, segment):\n",
    "        \"\"\"Write a single segment to the output file.\"\"\"\n",
    "        if not self.file_handle:\n",
    "            return\n",
    "        \n",
    "        self.segment_count += 1\n",
    "        \n",
    "        if self.format_type == \"txt\":\n",
    "            if self.multilingual and hasattr(segment, \"language\"):\n",
    "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\\\\\n\")\n",
    "            else:\n",
    "                self.file_handle.write(f\"{segment.text.strip()}\\\\\\\\n\")\n",
    "        \n",
    "        elif self.format_type == \"srt\":\n",
    "            self.file_handle.write(f\"{self.segment_count}\\\\\\\\n\")\n",
    "            start = format_timestamp(segment.start).replace(\".\", \",\")\n",
    "            end = format_timestamp(segment.end).replace(\".\", \",\")\n",
    "            self.file_handle.write(f\"{start} --> {end}\\\\\\\\n\")\n",
    "            if self.multilingual and hasattr(segment, \"language\"):\n",
    "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\\\\\n\\\\\\\\n\")\n",
    "            else:\n",
    "                self.file_handle.write(f\"{segment.text.strip()}\\\\\\\\n\\\\\\\\n\")\n",
    "        \n",
    "        elif self.format_type == \"vtt\":\n",
    "            start = format_timestamp(segment.start)\n",
    "            end = format_timestamp(segment.end)\n",
    "            self.file_handle.write(f\"{start} --> {end}\\\\\\\\n\")\n",
    "            if self.multilingual and hasattr(segment, \"language\"):\n",
    "                self.file_handle.write(f\"[{segment.language}] {segment.text.strip()}\\\\\\\\n\\\\\\\\n\")\n",
    "            else:\n",
    "                self.file_handle.write(f\"{segment.text.strip()}\\\\\\\\n\\\\\\\\n\")\n",
    "        \n",
    "        self.file_handle.flush()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the output file.\"\"\"\n",
    "        if self.file_handle:\n",
    "            self.file_handle.close()\n",
    "\n",
    "def detect_device_and_compute_type() -> Tuple[str, str]:\n",
    "    \"\"\"Detect if GPU is available and return appropriate device and compute type.\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            console.print(f\"[green]✓[/green] GPU detected: {gpu_name}\")\n",
    "            return \"cuda\", \"float16\"\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    console.print(\"[yellow]ℹ[/yellow] Using CPU for transcription\")\n",
    "    return \"cpu\", \"int8\"\n",
    "\n",
    "def load_whisper_model_with_retry(model_size: str, device: str, compute_type: str, max_retries: int = 3):\n",
    "    \"\"\"Load Whisper model with retry logic for handling Hugging Face connectivity issues.\"\"\"\n",
    "    import time\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            console.print(f\"[cyan]Loading model (attempt {attempt + 1}/{max_retries})...[/cyan]\")\n",
    "            \n",
    "            # Try different loading strategies\n",
    "            try:\n",
    "                # First try: Normal loading with local_files_only=False\n",
    "                model = WhisperModel(\n",
    "                    model_size, \n",
    "                    device=device, \n",
    "                    compute_type=compute_type,\n",
    "                    local_files_only=False\n",
    "                )\n",
    "                return model\n",
    "            except Exception as e1:\n",
    "                console.print(f\"[yellow]Standard loading failed: {str(e1)[:100]}...[/yellow]\")\n",
    "                \n",
    "                # Second try: Download path explicitly\n",
    "                try:\n",
    "                    # Set environment variable to avoid the HF token warning\n",
    "                    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "                    \n",
    "                    # Try with download_root\n",
    "                    download_root = \"/content/whisper_models\"\n",
    "                    os.makedirs(download_root, exist_ok=True)\n",
    "                    \n",
    "                    model = WhisperModel(\n",
    "                        model_size,\n",
    "                        device=device,\n",
    "                        compute_type=compute_type,\n",
    "                        download_root=download_root\n",
    "                    )\n",
    "                    return model\n",
    "                except Exception as e2:\n",
    "                    console.print(f\"[yellow]Download root method failed: {str(e2)[:100]}...[/yellow]\")\n",
    "                    \n",
    "                    # Third try: Use alternative loading\n",
    "                    if attempt < max_retries - 1:\n",
    "                        wait_time = (attempt + 1) * 5\n",
    "                        console.print(f\"[yellow]Waiting {wait_time} seconds before retry...[/yellow]\")\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        raise Exception(f\"Failed to load model after {max_retries} attempts\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                console.print(f\"[red]Failed to load model: {e}[/red]\")\n",
    "                console.print(\"[yellow]Troubleshooting tips:[/yellow]\")\n",
    "                console.print(\"1. Try restarting the Colab runtime\")\n",
    "                console.print(\"2. Check your internet connection\")\n",
    "                console.print(\"3. Try a different model size (e.g., 'tiny' or 'small')\")\n",
    "                console.print(\"4. Clear Colab cache: !rm -rf /root/.cache/huggingface\")\n",
    "                raise\n",
    "    \n",
    "    return None\n",
    "\n",
    "def transcribe_file_with_progress(\n",
    "    audio_file: Path,\n",
    "    model: WhisperModel,\n",
    "    output_dir: Path,\n",
    "    language: str = \"auto\",\n",
    "    output_format: str = \"txt\",\n",
    "    multilingual: bool = False,\n",
    "    keepalive: Optional[ColabKeepalive] = None,\n",
    "    progress: Optional[Progress] = None,\n",
    "    task_id: Optional[int] = None,\n",
    "    eta_column: Optional[RemainingAudioDurationColumn] = None,\n",
    "    checkpoint: Optional[TranscriptionCheckpoint] = None,\n",
    "    resume_position: float = 0\n",
    ") -> Dict:\n",
    "    \"\"\"Transcribe a single audio file with segment-based progress tracking.\"\"\"\n",
    "    \n",
    "    # Get audio duration\n",
    "    audio_duration = get_audio_duration(audio_file)\n",
    "    \n",
    "    # Prepare output file\n",
    "    output_file = output_dir / f\"{audio_file.stem}.{output_format}\"\n",
    "    \n",
    "    # Create writer\n",
    "    writer = StreamingTranscriptionWriter(output_file, output_format, multilingual)\n",
    "    \n",
    "    # Start transcription\n",
    "    console.print(f\"[cyan]Processing:[/cyan] {audio_file.name} ({format_duration(audio_duration)})\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Update keepalive status\n",
    "    if keepalive:\n",
    "        keepalive.update_status(f\"Transcribing {audio_file.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Transcribe\n",
    "        segments_iterator, info = model.transcribe(\n",
    "            str(audio_file),\n",
    "            language=LANGUAGE_MAP.get(language),\n",
    "            beam_size=5,\n",
    "            vad_filter=True,\n",
    "            vad_parameters=dict(min_silence_duration_ms=500),\n",
    "            multilingual=multilingual\n",
    "        )\n",
    "        \n",
    "        # Process segments with progress tracking\n",
    "        segment_count = 0\n",
    "        audio_position = 0\n",
    "        session_start_time = time.time()\n",
    "        \n",
    "        # Update progress bar total if available\n",
    "        if progress and task_id is not None:\n",
    "            progress.update(task_id, total=info.duration)\n",
    "        \n",
    "        for segment in segments_iterator:\n",
    "            # Skip if resuming and segment is before resume position\n",
    "            if resume_position > 0 and segment.end <= resume_position:\n",
    "                continue\n",
    "                \n",
    "            # Write segment\n",
    "            writer.write_segment(segment)\n",
    "            segment_count += 1\n",
    "            audio_position = segment.end\n",
    "            \n",
    "            # Update checkpoint\n",
    "            if checkpoint:\n",
    "                segment_data = {\n",
    "                    \"text\": segment.text,\n",
    "                    \"start\": segment.start,\n",
    "                    \"end\": segment.end,\n",
    "                    \"language\": getattr(segment, \"language\", None)\n",
    "                }\n",
    "                checkpoint.update_progress(segment_data, audio_position)\n",
    "            \n",
    "            # Update progress\n",
    "            if progress and task_id is not None:\n",
    "                progress.update(task_id, completed=audio_position)\n",
    "                \n",
    "                # Calculate and update ETA\n",
    "                if eta_column and audio_position > 5:  # Wait for 5 seconds before calculating ETA\n",
    "                    elapsed_time = time.time() - session_start_time\n",
    "                    rate = audio_position / elapsed_time\n",
    "                    if rate > 0:\n",
    "                        remaining_audio = info.duration - audio_position\n",
    "                        eta = remaining_audio / rate\n",
    "                        eta_column.set_eta(task_id, eta)\n",
    "            \n",
    "            # Update keepalive with segment info\n",
    "            if keepalive and segment_count % 5 == 0:  # Update every 5 segments\n",
    "                keepalive.update_status(\n",
    "                    f\"Transcribing {audio_file.name} - {segment_count} segments, \"\n",
    "                    f\"{audio_position:.1f}s/{info.duration:.1f}s ({audio_position/info.duration*100:.1f}%)\"\n",
    "                )\n",
    "                \n",
    "                            # Periodic memory cleanup to prevent kernel crashes\n",
    "            if segment_count % 100 == 0:\n",
    "                gc.collect()\n",
    "                try:\n",
    "                    import torch\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Close writer\n",
    "        writer.close()\n",
    "        \n",
    "        # Calculate stats\n",
    "        process_time = time.time() - start_time\n",
    "        speed = info.duration / process_time if process_time > 0 else 0\n",
    "        \n",
    "        # Final progress update\n",
    "        if progress and task_id is not None:\n",
    "            progress.update(task_id, completed=info.duration)\n",
    "        \n",
    "        console.print(\n",
    "            f\"[green]✓[/green] {audio_file.name} \"\n",
    "            f\"[dim]({info.duration:.1f}s @ {speed:.1f}x speed, {segment_count} segments)[/dim]\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"file\": audio_file.name,\n",
    "            \"duration\": info.duration,\n",
    "            \"segments\": segment_count,\n",
    "            \"process_time\": process_time,\n",
    "            \"speed\": speed,\n",
    "            \"output_file\": str(output_file),\n",
    "            \"detected_language\": info.language if language == \"auto\" else language\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        writer.close()\n",
    "        console.print(f\"[red]✗[/red] Error processing {audio_file.name}: {e}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"file\": audio_file.name,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "def find_audio_files(input_path: Path) -> List[Path]:\n",
    "    \"\"\"Find all audio files in the given path.\"\"\"\n",
    "    audio_files = []\n",
    "    \n",
    "    if input_path.is_file():\n",
    "        if input_path.suffix.lower() in AUDIO_EXTENSIONS:\n",
    "            audio_files.append(input_path)\n",
    "    else:\n",
    "        for ext in AUDIO_EXTENSIONS:\n",
    "            audio_files.extend(input_path.glob(f\"*{ext}\"))\n",
    "            audio_files.extend(input_path.glob(f\"*{ext.upper()}\"))\n",
    "    \n",
    "    return sorted(audio_files)\n",
    "\n",
    "def transcribe_folder(\n",
    "    input_path: Path,\n",
    "    output_path: Path,\n",
    "    model_size: str = \"base\",\n",
    "    language: str = \"auto\",\n",
    "    output_format: str = \"txt\",\n",
    "    multilingual: bool = False,\n",
    "    checkpoint_dir: Optional[Path] = None\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Transcribe all audio files in a folder with checkpoint support.\"\"\"\n",
    "    \n",
    "    # Set checkpoint directory\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = output_path / \".checkpoints\"\n",
    "    \n",
    "    # Initialize checkpoint\n",
    "    checkpoint = TranscriptionCheckpoint(checkpoint_dir)\n",
    "    \n",
    "    # Check for existing checkpoint\n",
    "    resume_info = None\n",
    "    if checkpoint.load():\n",
    "        console.print(Panel(\n",
    "            f\"[yellow]Found previous transcription checkpoint[/yellow]\\\\\\\\n\"\n",
    "            f\"Completed files: {len(checkpoint.state['files_completed'])}\\\\\\\\n\"\n",
    "            f\"Timestamp: {checkpoint.state['timestamp']}\",\n",
    "            title=\"[bold cyan]Resume Transcription?[/bold cyan]\",\n",
    "            border_style=\"cyan\"\n",
    "        ))\n",
    "        \n",
    "        try:\n",
    "            # In Colab, default to resume to avoid losing progress\n",
    "            resume = True\n",
    "            console.print(\"[green]Resuming from checkpoint...[/green]\")\n",
    "        except:\n",
    "            resume = True\n",
    "            \n",
    "        if resume:\n",
    "            resume_info = checkpoint.get_resume_info()\n",
    "        else:\n",
    "            checkpoint.clear()\n",
    "    \n",
    "    # Find audio files\n",
    "    audio_files = find_audio_files(input_path)\n",
    "    \n",
    "    if not audio_files:\n",
    "        console.print(\"[red]No audio files found![/red]\")\n",
    "        return []\n",
    "    \n",
    "    # Filter out completed files if resuming\n",
    "    if resume_info and resume_info[\"completed_files\"]:\n",
    "        original_count = len(audio_files)\n",
    "        audio_files = [f for f in audio_files if f.name not in resume_info[\"completed_files\"]]\n",
    "        console.print(f\"[green]Skipping {original_count - len(audio_files)} already completed files[/green]\")\n",
    "    \n",
    "    console.print(f\"[green]Found {len(audio_files)} audio files to process[/green]\")\n",
    "    \n",
    "    # Analyze total audio duration\n",
    "    total_duration = 0\n",
    "    console.print(\"[cyan]Analyzing audio files...[/cyan]\")\n",
    "    for audio_file in audio_files:\n",
    "        duration = get_audio_duration(audio_file)\n",
    "        total_duration += duration\n",
    "        console.print(f\"  • {audio_file.name}: {format_duration(duration)}\")\n",
    "    \n",
    "    console.print(f\"[green]Total audio duration: {format_duration(total_duration)}[/green]\\\\\\\\n\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load model with retry logic\n",
    "    device, compute_type = detect_device_and_compute_type()\n",
    "    console.print(f\"[cyan]Loading Whisper {model_size} model...[/cyan]\")\n",
    "    \n",
    "    try:\n",
    "        with console.status(\"[bold cyan]Loading model...[/bold cyan]\"):\n",
    "            model = load_whisper_model_with_retry(model_size, device=device, compute_type=compute_type)\n",
    "        \n",
    "        console.print(f\"[green]✓[/green] Model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        console.print(f\"[red]Error loading model: {e}[/red]\")\n",
    "        console.print(\"\\\\\\\\n[yellow]Alternative solution:[/yellow]\")\n",
    "        console.print(\"Try running this command first to clear cache:\")\n",
    "        console.print(\"[cyan]!rm -rf /root/.cache/huggingface[/cyan]\")\n",
    "        console.print(\"Then restart the runtime and try again.\")\n",
    "        return []\n",
    "    \n",
    "    # Initialize keepalive\n",
    "    keepalive = ColabKeepalive()\n",
    "    keepalive.start()\n",
    "    \n",
    "    # Process files with enhanced progress\n",
    "    results = []\n",
    "    eta_column = RemainingAudioDurationColumn()\n",
    "    \n",
    "    try:\n",
    "        with Progress(\n",
    "            SpinnerColumn(spinner_name=\"dots12\", style=\"cyan\"),\n",
    "            TextColumn(\"[bold blue]{task.description}\"),\n",
    "            BarColumn(bar_width=40, style=\"cyan\", complete_style=\"green\"),\n",
    "            TaskProgressColumn(),\n",
    "            \"•\",\n",
    "            TimeElapsedColumn(),\n",
    "            \"•\",\n",
    "            eta_column,\n",
    "            console=console,\n",
    "            refresh_per_second=1\n",
    "        ) as progress:\n",
    "            # Main task for overall progress\n",
    "            main_task = progress.add_task(\n",
    "                f\"[cyan]Overall Progress ({len(audio_files)} files)\", \n",
    "                total=total_duration\n",
    "            )\n",
    "            \n",
    "            # Individual file task\n",
    "            file_task = progress.add_task(\"[yellow]Current file\", visible=False)\n",
    "            \n",
    "            total_processed = 0\n",
    "            \n",
    "            for idx, audio_file in enumerate(audio_files, 1):\n",
    "                # Check if this is the file we need to resume\n",
    "                resume_position = 0\n",
    "                if resume_info and resume_info[\"current_file\"] == audio_file.name:\n",
    "                    resume_position = resume_info[\"current_position\"]\n",
    "                    console.print(f\"[yellow]Resuming {audio_file.name} from position {resume_position:.1f}s[/yellow]\")\n",
    "                \n",
    "                # Set current file in checkpoint\n",
    "                checkpoint.set_current_file(audio_file.name)\n",
    "                \n",
    "                # Update file task\n",
    "                progress.update(\n",
    "                    file_task, \n",
    "                    description=f\"[yellow]File {idx}/{len(audio_files)}: {audio_file.name}\",\n",
    "                    visible=True,\n",
    "                    completed=resume_position\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    # Transcribe with progress\n",
    "                    result = transcribe_file_with_progress(\n",
    "                        audio_file, model, output_path, \n",
    "                        language, output_format, multilingual,\n",
    "                        keepalive, progress, file_task, eta_column,\n",
    "                        checkpoint, resume_position\n",
    "                    )\n",
    "                    \n",
    "                    results.append(result)\n",
    "                    \n",
    "                    # Update overall progress\n",
    "                    if result[\"success\"]:\n",
    "                        total_processed += result[\"duration\"]\n",
    "                        progress.update(main_task, completed=total_processed)\n",
    "                        # Mark file as complete in checkpoint\n",
    "                        checkpoint.mark_file_complete(audio_file.name)\n",
    "                    \n",
    "                    # Hide file task between files\n",
    "                    progress.update(file_task, visible=False)\n",
    "                    \n",
    "                    # Force save checkpoint after each file\n",
    "                    checkpoint.save()\n",
    "                    \n",
    "                    # Memory cleanup between files\n",
    "                    gc.collect()\n",
    "                    try:\n",
    "                        import torch\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    console.print(f\"[red]Error processing {audio_file.name}: {e}[/red]\")\n",
    "                    results.append({\n",
    "                        \"success\": False,\n",
    "                        \"file\": audio_file.name,\n",
    "                        \"error\": str(e)\n",
    "                    })\n",
    "                    # Continue with next file even if one fails\n",
    "                    continue\n",
    "            \n",
    "            # Ensure main task shows completion\n",
    "            progress.update(main_task, completed=total_duration)\n",
    "    \n",
    "    finally:\n",
    "        # Stop keepalive\n",
    "        keepalive.stop()\n",
    "        print()  # Clear the keepalive line\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_results_summary(results: List[Dict]):\n",
    "    \"\"\"Display a summary of transcription results.\"\"\"\n",
    "    if not results:\n",
    "        return\n",
    "    \n",
    "    # Create summary table\n",
    "    table = Table(title=\"📊 Transcription Results\", show_header=True, header_style=\"bold cyan\")\n",
    "    table.add_column(\"File\", style=\"cyan\", width=30)\n",
    "    table.add_column(\"Status\", style=\"green\")\n",
    "    table.add_column(\"Duration\", justify=\"right\")\n",
    "    table.add_column(\"Segments\", justify=\"right\")\n",
    "    table.add_column(\"Speed\", justify=\"right\")\n",
    "    \n",
    "    successful = 0\n",
    "    failed = 0\n",
    "    total_duration = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    for result in results:\n",
    "        if result[\"success\"]:\n",
    "            successful += 1\n",
    "            total_duration += result[\"duration\"]\n",
    "            total_time += result[\"process_time\"]\n",
    "            \n",
    "            table.add_row(\n",
    "                result[\"file\"][:30] + \"...\" if len(result[\"file\"]) > 30 else result[\"file\"],\n",
    "                \"✅ Success\",\n",
    "                format_duration(result[\"duration\"]),\n",
    "                str(result[\"segments\"]),\n",
    "                f\"{result['speed']:.1f}x\"\n",
    "            )\n",
    "        else:\n",
    "            failed += 1\n",
    "            error_msg = str(result[\"error\"])[:20] + \"...\" if len(str(result[\"error\"])) > 20 else str(result[\"error\"])\n",
    "            table.add_row(\n",
    "                result[\"file\"][:30] + \"...\" if len(result[\"file\"]) > 30 else result[\"file\"],\n",
    "                f\"❌ {error_msg}\",\n",
    "                \"-\",\n",
    "                \"-\",\n",
    "                \"-\"\n",
    "            )\n",
    "    \n",
    "    console.print(\"\\\\\\\\n\")\n",
    "    console.print(table)\n",
    "    \n",
    "    # Summary statistics\n",
    "    if successful > 0:\n",
    "        avg_speed = total_duration / total_time if total_time > 0 else 0\n",
    "        console.print(\"\\\\\\\\n\")\n",
    "        console.print(Panel(\n",
    "            f\"[bold]Summary:[/bold]\\\\\\\\n\\\\\\\\n\"\n",
    "            f\"✅ Successful: {successful} files\\\\\\\\n\"\n",
    "            f\"❌ Failed: {failed} files\\\\\\\\n\"\n",
    "            f\"⏱️  Total audio: {format_duration(total_duration)}\\\\\\\\n\"\n",
    "            f\"⚡ Processing time: {format_duration(total_time)}\\\\\\\\n\"\n",
    "            f\"🚀 Average speed: {avg_speed:.1f}x realtime\",\n",
    "            title=\"[bold green]Transcription Complete![/bold green]\",\n",
    "            border_style=\"green\"\n",
    "        ))\n",
    "'''\n",
    "\n",
    "with open('/content/transcript_pkg/file_transcribe.py', 'w') as f:\n",
    "    f.write(file_transcribe_code)\n",
    "\n",
    "print(\"✅ Enhanced file_transcribe.py created with segment progress tracking and keepalive!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ⚠️ Troubleshooting: Model Loading Issues\n",
    "\n",
    "If you encounter a **\"502 Bad Gateway\"** or similar error when loading the model, this is usually due to Hugging Face connectivity issues. The notebook now includes retry logic to handle this automatically. However, if the issue persists:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear Hugging Face cache if you encounter model loading errors\n",
    "# Uncomment and run if needed:\n",
    "# !rm -rf /root/.cache/huggingface\n",
    "# !rm -rf /content/whisper_models\n",
    "\n",
    "# After running this, restart the runtime: Runtime → Restart runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Configure Transcription Settings\n",
    "\n",
    "Modify the parameters below according to your needs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters - MODIFY THESE AS NEEDED\n",
    "\n",
    "# Input path in Google Drive (can be a file or folder)\n",
    "INPUT_PATH = \"/content/drive/MyDrive/AudioFiles\"  # @param {type:\"string\"}\n",
    "\n",
    "# Output path in Google Drive  \n",
    "OUTPUT_PATH = \"/content/drive/MyDrive/Transcriptions\"  # @param {type:\"string\"}\n",
    "\n",
    "# Model size: tiny, base, small, medium, large\n",
    "MODEL_SIZE = \"base\"  # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large\"]\n",
    "\n",
    "# Language: en (English), pt (Portuguese), auto (auto-detect)\n",
    "LANGUAGE = \"auto\"  # @param [\"auto\", \"en\", \"pt\"]\n",
    "\n",
    "# Output format: txt, srt, vtt\n",
    "OUTPUT_FORMAT = \"txt\"  # @param [\"txt\", \"srt\", \"vtt\"]\n",
    "\n",
    "# Enable multilingual mode (shows language for each segment)\n",
    "MULTILINGUAL = False  # @param {type:\"boolean\"}\n",
    "\n",
    "print(\"📋 Configuration:\")\n",
    "print(f\"  Input: {INPUT_PATH}\")\n",
    "print(f\"  Output: {OUTPUT_PATH}\")\n",
    "print(f\"  Model: {MODEL_SIZE}\")\n",
    "print(f\"  Language: {LANGUAGE}\")\n",
    "print(f\"  Format: {OUTPUT_FORMAT}\")\n",
    "print(f\"  Multilingual: {MULTILINGUAL}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Optional: Clear Previous Checkpoints\n",
    "\n",
    "If you want to start fresh and clear any previous checkpoints, run this cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clear checkpoints to start fresh\n",
    "# Uncomment the lines below if you want to remove previous checkpoint data\n",
    "\n",
    "# import shutil\n",
    "# checkpoint_path = Path(OUTPUT_PATH) / \".checkpoints\"\n",
    "# if checkpoint_path.exists():\n",
    "#     shutil.rmtree(checkpoint_path)\n",
    "#     print(\"✅ Checkpoints cleared!\")\n",
    "# else:\n",
    "#     print(\"ℹ️ No checkpoints found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 5: Run Transcription\n",
    "\n",
    "Execute the cell below to start the transcription process. The notebook will:\n",
    "- Keep your Colab connection alive during long transcriptions\n",
    "- Show segment-by-segment progress with ETA\n",
    "- Automatically handle connection issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('/content')\n",
    "\n",
    "from transcript_pkg.file_transcribe import transcribe_folder, display_results_summary\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# Convert paths\n",
    "input_path = Path(INPUT_PATH)\n",
    "output_path = Path(OUTPUT_PATH)\n",
    "\n",
    "# Check if input exists\n",
    "if not input_path.exists():\n",
    "    console.print(f\"[red]Error: Input path does not exist: {INPUT_PATH}[/red]\")\n",
    "    console.print(\"[yellow]Please check your INPUT_PATH and ensure the folder/file exists in your Google Drive.[/yellow]\")\n",
    "else:\n",
    "    # Run transcription\n",
    "    console.print(Panel(\n",
    "        \"[bold green]Starting Transcription Process[/bold green]\\n\\n\"\n",
    "        \"This may take a while depending on the size and number of files.\\n\"\n",
    "        \"The process will use GPU acceleration if available.\\n\\n\"\n",
    "        \"[cyan]Features:[/cyan]\\n\"\n",
    "        \"• Segment-by-segment progress tracking\\n\"\n",
    "        \"• Real-time ETA calculations\\n\"\n",
    "        \"• Connection keepalive for long files\\n\"\n",
    "        \"• Automatic checkpointing to Google Drive\\n\"\n",
    "        \"• Resume capability if kernel restarts\\n\"\n",
    "        \"• Memory management to prevent crashes\",\n",
    "        title=\"🎙️ Transcription\",\n",
    "        border_style=\"green\"\n",
    "    ))\n",
    "    \n",
    "    results = transcribe_folder(\n",
    "        input_path=input_path,\n",
    "        output_path=output_path,\n",
    "        model_size=MODEL_SIZE,\n",
    "        language=LANGUAGE,\n",
    "        output_format=OUTPUT_FORMAT,\n",
    "        multilingual=MULTILINGUAL\n",
    "    )\n",
    "    \n",
    "    # Display results summary\n",
    "    if results:\n",
    "        display_results_summary(results)\n",
    "        \n",
    "        # Show output location\n",
    "        console.print(f\"\\n📁 [bold cyan]Output files saved to:[/bold cyan] {output_path}\")\n",
    "        console.print(\"[dim]You can find your transcriptions in the specified Google Drive folder.[/dim]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 6: View Transcription Files\n",
    "\n",
    "List and preview the transcribed files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all transcription files created\n",
    "import os\n",
    "from rich.table import Table\n",
    "\n",
    "if output_path.exists():\n",
    "    files = list(output_path.glob(f\"*.{OUTPUT_FORMAT}\"))\n",
    "    \n",
    "    if files:\n",
    "        # Create a table to display files\n",
    "        table = Table(title=f\"📄 Transcription Files ({len(files)} total)\", show_header=True)\n",
    "        table.add_column(\"File Name\", style=\"cyan\")\n",
    "        table.add_column(\"Size\", justify=\"right\", style=\"yellow\")\n",
    "        table.add_column(\"Path\", style=\"dim\")\n",
    "        \n",
    "        for file in sorted(files):\n",
    "            size_kb = os.path.getsize(file) / 1024\n",
    "            table.add_row(\n",
    "                file.name,\n",
    "                f\"{size_kb:.1f} KB\",\n",
    "                str(file.relative_to(Path(\"/content/drive\")))\n",
    "            )\n",
    "        \n",
    "        console.print(table)\n",
    "    else:\n",
    "        console.print(\"[yellow]No transcription files found in the output directory.[/yellow]\")\n",
    "else:\n",
    "    console.print(\"[red]Output directory does not exist.[/red]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 7: Preview a Transcription\n",
    "\n",
    "Preview the content of the first transcription file:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Dealing with Colab Kernel Restarts\n",
    "\n",
    "If you experience kernel restarts during long transcriptions:\n",
    "\n",
    "1. **Automatic Resume**: The notebook automatically saves progress to Google Drive. When you re-run Step 5, it will resume from where it left off.\n",
    "\n",
    "2. **Check GPU Memory**: Monitor GPU usage with:\n",
    "   ```python\n",
    "   !nvidia-smi\n",
    "   ```\n",
    "\n",
    "3. **Process Smaller Batches**: If processing many files, consider splitting them into smaller folders.\n",
    "\n",
    "4. **Use Smaller Models**: If you encounter memory issues, try using a smaller model (e.g., 'tiny' or 'base' instead of 'large').\n",
    "\n",
    "5. **Save Intermediate Results**: The notebook saves transcriptions as it completes each file, so you don't lose progress.\n",
    "\n",
    "6. **Monitor Checkpoints**: Check the `.checkpoints` folder in your output directory to see the current progress state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a transcription file\n",
    "if output_path.exists():\n",
    "    files = list(output_path.glob(f\"*.{OUTPUT_FORMAT}\"))\n",
    "    \n",
    "    if files:\n",
    "        # Let user select which file to preview\n",
    "        console.print(f\"\\n[cyan]Found {len(files)} transcription file(s). Showing preview of the first one.[/cyan]\")\n",
    "        \n",
    "        # Get the first file\n",
    "        preview_file = sorted(files)[0]\n",
    "        \n",
    "        console.print(f\"\\n[bold]File: {preview_file.name}[/bold]\\n\")\n",
    "        \n",
    "        # Read and display content (limit to first 1000 characters for preview)\n",
    "        try:\n",
    "            with open(preview_file, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                preview_length = 1000\n",
    "                \n",
    "                if len(content) > preview_length:\n",
    "                    preview = content[:preview_length] + \"\\n\\n[... truncated for preview ...]\"\n",
    "                else:\n",
    "                    preview = content\n",
    "                \n",
    "                console.print(Panel(\n",
    "                    preview,\n",
    "                    title=f\"📄 {preview_file.name}\",\n",
    "                    border_style=\"blue\",\n",
    "                    padding=(1, 2)\n",
    "                ))\n",
    "                \n",
    "                console.print(f\"\\n[dim]Full file location: {preview_file}[/dim]\")\n",
    "                console.print(f\"[dim]Total content length: {len(content)} characters[/dim]\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]Error reading file: {e}[/red]\")\n",
    "    else:\n",
    "        console.print(\"[yellow]No transcription files found to preview.[/yellow]\")\n",
    "else:\n",
    "    console.print(\"[red]Output directory does not exist.[/red]\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
